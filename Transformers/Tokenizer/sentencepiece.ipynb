{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BytesIO',\n",
       " 'ImmutableNBestSentencePieceText',\n",
       " 'ImmutableSentencePieceText',\n",
       " 'ImmutableSentencePieceText_ImmutableSentencePiece',\n",
       " 'SentencePieceNormalizer',\n",
       " 'SentencePieceProcessor',\n",
       " 'SentencePieceTrainer',\n",
       " 'SetMinLogLevel',\n",
       " 'SetRandomGeneratorSeed',\n",
       " 'StringIO',\n",
       " '_LogStream',\n",
       " '_SwigNonDynamicMeta',\n",
       " '_add_snake_case',\n",
       " '_batchnize',\n",
       " '_sentencepiece',\n",
       " '_sentencepiece_normalizer_init_native',\n",
       " '_sentencepiece_processor_init_native',\n",
       " '_swig_add_metaclass',\n",
       " '_swig_python_version_info',\n",
       " '_swig_repr',\n",
       " '_swig_setattr_nondynamic_class_variable',\n",
       " '_swig_setattr_nondynamic_instance_variable',\n",
       " '_version',\n",
       " 'csv',\n",
       " 'm',\n",
       " 'os',\n",
       " 're',\n",
       " 'set_min_log_level',\n",
       " 'set_random_generator_seed',\n",
       " 'sys']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(spm) if not i.startswith(\"__\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Llama-2-7b-chat-hf/tokenizer.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x000002101A136580> >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model = spm.SentencePieceProcessor(model_file=model_path)\n",
    "sp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CalculateEntropy',\n",
       " 'Decode',\n",
       " 'DecodeIds',\n",
       " 'DecodeIdsAsImmutableProto',\n",
       " 'DecodeIdsAsSerializedProto',\n",
       " 'DecodePieces',\n",
       " 'DecodePiecesAsImmutableProto',\n",
       " 'DecodePiecesAsSerializedProto',\n",
       " 'Detokenize',\n",
       " 'Encode',\n",
       " 'EncodeAsIds',\n",
       " 'EncodeAsImmutableProto',\n",
       " 'EncodeAsPieces',\n",
       " 'EncodeAsSerializedProto',\n",
       " 'GetPieceSize',\n",
       " 'GetScore',\n",
       " 'IdToPiece',\n",
       " 'Init',\n",
       " 'IsByte',\n",
       " 'IsControl',\n",
       " 'IsUnknown',\n",
       " 'IsUnused',\n",
       " 'Load',\n",
       " 'LoadFromFile',\n",
       " 'LoadFromSerializedProto',\n",
       " 'LoadVocabulary',\n",
       " 'NBestEncode',\n",
       " 'NBestEncodeAsIds',\n",
       " 'NBestEncodeAsImmutableProto',\n",
       " 'NBestEncodeAsPieces',\n",
       " 'NBestEncodeAsSerializedProto',\n",
       " 'Normalize',\n",
       " 'OverrideNormalizerSpec',\n",
       " 'PieceToId',\n",
       " 'ResetVocabulary',\n",
       " 'SampleEncodeAndScore',\n",
       " 'SampleEncodeAndScoreAsIds',\n",
       " 'SampleEncodeAndScoreAsImmutableProto',\n",
       " 'SampleEncodeAndScoreAsPieces',\n",
       " 'SampleEncodeAndScoreAsSerializedProto',\n",
       " 'SampleEncodeAsIds',\n",
       " 'SampleEncodeAsImmutableProto',\n",
       " 'SampleEncodeAsPieces',\n",
       " 'SampleEncodeAsSerializedProto',\n",
       " 'SetDecodeExtraOptions',\n",
       " 'SetEncodeExtraOptions',\n",
       " 'SetVocabulary',\n",
       " 'Tokenize',\n",
       " 'bos_id',\n",
       " 'calculate_entropy',\n",
       " 'decode',\n",
       " 'decode_ids',\n",
       " 'decode_ids_as_immutable_proto',\n",
       " 'decode_ids_as_serialized_proto',\n",
       " 'decode_pieces',\n",
       " 'decode_pieces_as_immutable_proto',\n",
       " 'decode_pieces_as_serialized_proto',\n",
       " 'detokenize',\n",
       " 'encode',\n",
       " 'encode_as_ids',\n",
       " 'encode_as_immutable_proto',\n",
       " 'encode_as_pieces',\n",
       " 'encode_as_serialized_proto',\n",
       " 'eos_id',\n",
       " 'get_piece_size',\n",
       " 'get_score',\n",
       " 'id_to_piece',\n",
       " 'init',\n",
       " 'is_byte',\n",
       " 'is_control',\n",
       " 'is_unknown',\n",
       " 'is_unused',\n",
       " 'load',\n",
       " 'load_from_file',\n",
       " 'load_from_serialized_proto',\n",
       " 'load_vocabulary',\n",
       " 'nbest_encode',\n",
       " 'nbest_encode_as_ids',\n",
       " 'nbest_encode_as_immutable_proto',\n",
       " 'nbest_encode_as_pieces',\n",
       " 'nbest_encode_as_serialized_proto',\n",
       " 'normalize',\n",
       " 'override_normalizer_spec',\n",
       " 'pad_id',\n",
       " 'piece_size',\n",
       " 'piece_to_id',\n",
       " 'reset_vocabulary',\n",
       " 'sample_encode_and_score',\n",
       " 'sample_encode_and_score_as_ids',\n",
       " 'sample_encode_and_score_as_immutable_proto',\n",
       " 'sample_encode_and_score_as_pieces',\n",
       " 'sample_encode_and_score_as_serialized_proto',\n",
       " 'sample_encode_as_ids',\n",
       " 'sample_encode_as_immutable_proto',\n",
       " 'sample_encode_as_pieces',\n",
       " 'sample_encode_as_serialized_proto',\n",
       " 'serialized_model_proto',\n",
       " 'set_decode_extra_options',\n",
       " 'set_encode_extra_options',\n",
       " 'set_vocabulary',\n",
       " 'this',\n",
       " 'thisown',\n",
       " 'tokenize',\n",
       " 'unk_id',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(sp_model) if not i.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, -1, 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.bos_id(), sp_model.eos_id(), sp_model.pad_id(), sp_model.unk_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '', ' ⁇ ')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.Decode([1]), sp_model.Decode([2]), sp_model.Decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 32000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.get_piece_size(), sp_model.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"零一二三四五六七八九十\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode / Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Encode in module sentencepiece:\n",
      "\n",
      "Encode(input, out_type=None, add_bos=None, add_eos=None, reverse=None, emit_unk_piece=None, enable_sampling=None, nbest_size=None, alpha=None, num_threads=None) method of sentencepiece.SentencePieceProcessor instance\n",
      "    Encode text input to segmented ids or tokens.\n",
      "    \n",
      "    Args:\n",
      "    input: input string. accepsts list of string.\n",
      "    out_type: output type. int or str.\n",
      "    add_bos: Add <s> to the result (Default = false)\n",
      "    add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
      "             reversing (if enabled).\n",
      "    reverse: Reverses the tokenized sequence (Default = false)\n",
      "    emit_unk_piece: Emits the unk literal string (Default = false)\n",
      "    nbest_size: sampling parameters for unigram. Invalid in BPE-Dropout.\n",
      "                nbest_size = {0,1}: No sampling is performed.\n",
      "                nbest_size > 1: samples from the nbest_size results.\n",
      "                nbest_size < 0: assuming that nbest_size is infinite and samples\n",
      "                from the all hypothesis (lattice) using\n",
      "                forward-filtering-and-backward-sampling algorithm.\n",
      "    alpha: Soothing parameter for unigram sampling, and merge probability for\n",
      "           BPE-dropout (probablity 'p' in BPE-dropout paper).\n",
      "    num_threads: the number of threads used in the batch processing (Default = -1).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sp_model.Encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 450, 4996, 17354, 1701, 29916, 432, 17204, 975, 278, 17366, 11203, 2],\n",
       " [1,\n",
       "  29871,\n",
       "  236,\n",
       "  158,\n",
       "  185,\n",
       "  30287,\n",
       "  30685,\n",
       "  30457,\n",
       "  30928,\n",
       "  30904,\n",
       "  31304,\n",
       "  31425,\n",
       "  31044,\n",
       "  31321,\n",
       "  30802,\n",
       "  2]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = sp_model.Encode(input=inputs, out_type=int, add_bos=True, add_eos=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>',\n",
       "  '▁The',\n",
       "  '▁quick',\n",
       "  '▁brown',\n",
       "  '▁fo',\n",
       "  'x',\n",
       "  '▁j',\n",
       "  'umps',\n",
       "  '▁over',\n",
       "  '▁the',\n",
       "  '▁lazy',\n",
       "  '▁dog',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  '▁',\n",
       "  '<0xE9>',\n",
       "  '<0x9B>',\n",
       "  '<0xB6>',\n",
       "  '一',\n",
       "  '二',\n",
       "  '三',\n",
       "  '四',\n",
       "  '五',\n",
       "  '六',\n",
       "  '七',\n",
       "  '八',\n",
       "  '九',\n",
       "  '十',\n",
       "  '</s>']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.Encode(input=inputs, out_type=str, add_bos=True, add_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 450, 4996, 17354, 1701, 29916, 432, 17204, 975, 278, 17366, 11203, 2],\n",
       " [1,\n",
       "  29871,\n",
       "  236,\n",
       "  158,\n",
       "  185,\n",
       "  30287,\n",
       "  30685,\n",
       "  30457,\n",
       "  30928,\n",
       "  30904,\n",
       "  31304,\n",
       "  31425,\n",
       "  31044,\n",
       "  31321,\n",
       "  30802,\n",
       "  2]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.Tokenize(input=inputs, out_type=int, add_bos=True, add_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[450, 4996, 17354, 1701, 29916, 432, 17204, 975, 278, 17366, 11203],\n",
       " [29871,\n",
       "  236,\n",
       "  158,\n",
       "  185,\n",
       "  30287,\n",
       "  30685,\n",
       "  30457,\n",
       "  30928,\n",
       "  30904,\n",
       "  31304,\n",
       "  31425,\n",
       "  31044,\n",
       "  31321,\n",
       "  30802]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用的Encode,返回ids\n",
    "sp_model.EncodeAsIds(input=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁The',\n",
       "  '▁quick',\n",
       "  '▁brown',\n",
       "  '▁fo',\n",
       "  'x',\n",
       "  '▁j',\n",
       "  'umps',\n",
       "  '▁over',\n",
       "  '▁the',\n",
       "  '▁lazy',\n",
       "  '▁dog'],\n",
       " ['▁',\n",
       "  '<0xE9>',\n",
       "  '<0x9B>',\n",
       "  '<0xB6>',\n",
       "  '一',\n",
       "  '二',\n",
       "  '三',\n",
       "  '四',\n",
       "  '五',\n",
       "  '六',\n",
       "  '七',\n",
       "  '八',\n",
       "  '九',\n",
       "  '十']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用的Encode,返回str\n",
    "sp_model.EncodeAsPieces(input=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Decode in module sentencepiece:\n",
      "\n",
      "Decode(input, out_type=<class 'str'>, num_threads=None) method of sentencepiece.SentencePieceProcessor instance\n",
      "    Decode processed id or token sequences.\n",
      "    \n",
      "    Args:\n",
      "      out_type: output type. str, bytes or 'serialized_proto' or 'immutable_proto' (Default = str)\n",
      "      num_threads: the number of threads used in the batch processing (Default = -1).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sp_model.Decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 450, 4996, 17354, 1701, 29916, 432, 17204, 975, 278, 17366, 11203, 2],\n",
       " [1,\n",
       "  29871,\n",
       "  236,\n",
       "  158,\n",
       "  185,\n",
       "  30287,\n",
       "  30685,\n",
       "  30457,\n",
       "  30928,\n",
       "  30904,\n",
       "  31304,\n",
       "  31425,\n",
       "  31044,\n",
       "  31321,\n",
       "  30802,\n",
       "  2]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认去掉特殊token\n",
    "sp_model.Decode([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog', '零一二三四五六七八九十']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model.Decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog', '零一二三四五六七八九十']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用的Decode,返回str\n",
    "sp_model.DecodeIds(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog', '零一二三四五六七八九十']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用的Decode,返回str\n",
    "sp_model.DecodePieces(sp_model.EncodeAsPieces(input=inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
