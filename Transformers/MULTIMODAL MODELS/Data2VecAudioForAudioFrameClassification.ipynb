{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    Data2VecAudioForAudioFrameClassification,\n",
    "    AutoProcessor,\n",
    "    AutoFeatureExtractor,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"facebook/data2vec-audio-base-960h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/ImageBind#usage\n",
    "\n",
    "For windows users, you might need to install librosa and soundfile for reading/writing audio files. (Thanks @congyue1977)\n",
    "\n",
    "`pip install soundfile librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
       "    num_rows: 73\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\"\n",
    ")\n",
    "dataset = dataset.sort(\"id\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'C:/Users/Administrator/.cache/huggingface/datasets/downloads/extracted/b49df5cb4e26d70a35c542fbe0eadc8bfee0f971809886d2131859668faeba1c/dev_clean/1272/128104\\\\1272-128104-0000.flac',\n",
       " 'audio': {'path': 'C:/Users/Administrator/.cache/huggingface/datasets/downloads/extracted/b49df5cb4e26d70a35c542fbe0eadc8bfee0f971809886d2131859668faeba1c/dev_clean/1272/128104\\\\1272-128104-0000.flac',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
       "         0.0010376 ]),\n",
       "  'sampling_rate': 16000},\n",
       " 'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL',\n",
       " 'speaker_id': 1272,\n",
       " 'chapter_id': 128104,\n",
       " 'id': '1272-128104-0000'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
       "        0.0010376 ]),\n",
       " array([-1.52587891e-04, -9.15527344e-05, -1.83105469e-04, ...,\n",
       "         9.76562500e-04,  9.46044922e-04, -4.88281250e-04])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get multi array\n",
    "[d[\"array\"] for d in dataset[:2][\"audio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL',\n",
       " \"NOR IS MISTER QUILTER'S MANNER LESS INTERESTING THAN HIS MATTER\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get multi text\n",
    "[d for d in dataset[:2][\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoProcessor(same as AutoFeatureExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"processor_class\": \"Wav2Vec2Processor\",\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='facebook/data2vec-audio-base-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor: AutoProcessor = AutoProcessor.from_pretrained(version)\n",
    "processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[0.0386, 0.0337, 0.0322,  ..., 0.0070, 0.0095, 0.0169]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0', dtype=torch.int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(\n",
    "    dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\"\n",
    ").to(device, torch.float16)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 93680])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '',\n",
       " 'E',\n",
       " 'T',\n",
       " 'A',\n",
       " 'O',\n",
       " 'N',\n",
       " 'I',\n",
       " 'H',\n",
       " 'S',\n",
       " 'R',\n",
       " 'D',\n",
       " 'L',\n",
       " 'U',\n",
       " 'M',\n",
       " 'W',\n",
       " 'C',\n",
       " 'F',\n",
       " 'G',\n",
       " 'Y',\n",
       " 'P',\n",
       " 'B',\n",
       " 'V',\n",
       " 'K',\n",
       " \"'\",\n",
       " 'X',\n",
       " 'J',\n",
       " 'Q',\n",
       " 'Z',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(range(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data2VecAudioForAudioFrameClassification\n",
    "\n",
    "Data2VecAudio Model with a frame classification head on top for tasks like Speaker Diarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Data2VecAudioForAudioFrameClassification were not initialized from the model checkpoint at facebook/data2vec-audio-base-960h and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data2VecAudioForAudioFrameClassification(\n",
       "  (data2vec_audio): Data2VecAudioModel(\n",
       "    (feature_extractor): Data2VecAudioFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Data2VecAudioConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x Data2VecAudioConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Data2VecAudioConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Data2VecAudioFeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Data2VecAudioEncoder(\n",
       "      (pos_conv_embed): Data2VecAudioPositionalConvEmbedding(\n",
       "        (layers): ModuleList(\n",
       "          (0-4): 5 x Data2VecAudioPositionalConvLayer(\n",
       "            (conv): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)\n",
       "            (padding): Data2VecAudioPadLayer()\n",
       "            (activation): GELUActivation()\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Data2VecAudioEncoderLayer(\n",
       "          (attention): Data2VecAudioAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Data2VecAudioFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: Data2VecAudioForAudioFrameClassification = (\n",
    "    Data2VecAudioForAudioFrameClassification.from_pretrained(\n",
    "        version, torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[ 7.5365e-02,  4.7647e-01],\n",
       "         [ 7.5365e-02,  4.7647e-01],\n",
       "         [ 7.5364e-02,  4.7647e-01],\n",
       "         [ 7.5365e-02,  4.7647e-01],\n",
       "         [ 7.5365e-02,  4.7647e-01],\n",
       "         [-5.3869e-02,  4.9465e-01],\n",
       "         [-2.8681e-02,  4.8524e-01],\n",
       "         [-6.2587e-03,  4.8217e-01],\n",
       "         [-1.9858e-02,  4.9937e-01],\n",
       "         [ 2.0373e-03,  4.8342e-01],\n",
       "         [-5.6541e-04,  4.7674e-01],\n",
       "         [-9.6416e-03,  4.8140e-01],\n",
       "         [-2.5676e-02,  4.9231e-01],\n",
       "         [-2.8853e-02,  4.9478e-01],\n",
       "         [-8.0962e-03,  4.8340e-01],\n",
       "         [-7.0779e-03,  4.7318e-01],\n",
       "         [ 2.0098e-02,  4.9051e-01],\n",
       "         [ 3.9949e-02,  4.8465e-01],\n",
       "         [ 7.1933e-02,  4.1313e-01],\n",
       "         [ 5.3954e-02,  3.3029e-01],\n",
       "         [ 4.6347e-02,  2.8744e-01],\n",
       "         [ 7.3757e-02,  2.5687e-01],\n",
       "         [ 9.0989e-02,  2.2813e-01],\n",
       "         [ 9.8402e-02,  1.8492e-01],\n",
       "         [ 1.2422e-01,  1.8679e-01],\n",
       "         [ 1.8969e-01,  2.6615e-01],\n",
       "         [ 1.8532e-01,  2.8455e-01],\n",
       "         [ 5.3918e-02,  3.0737e-01],\n",
       "         [-1.8886e-01, -1.8017e-02],\n",
       "         [-2.8720e-02,  6.1845e-01],\n",
       "         [ 6.5705e-02,  1.1955e-01],\n",
       "         [ 3.9534e-02,  1.2425e-01],\n",
       "         [ 1.5658e-01, -3.2130e-01],\n",
       "         [ 4.1341e-01,  1.3906e-01],\n",
       "         [-2.0846e-02, -1.7040e-01],\n",
       "         [-1.5620e-01,  4.9155e-01],\n",
       "         [-2.3903e-01,  3.6655e-01],\n",
       "         [-2.7840e-02, -1.3207e-01],\n",
       "         [-1.6254e-01, -1.2280e-02],\n",
       "         [-1.0770e-01,  2.8811e-01],\n",
       "         [ 4.3538e-02,  3.2602e-01],\n",
       "         [ 1.0928e-01,  3.4051e-02],\n",
       "         [ 7.2998e-02,  2.0462e-01],\n",
       "         [-3.5472e-01,  6.4829e-02],\n",
       "         [ 3.8920e-03,  7.7837e-02],\n",
       "         [-1.1843e-01,  1.5380e-01],\n",
       "         [-1.0405e-01,  4.9024e-01],\n",
       "         [ 7.9350e-02,  3.6295e-01],\n",
       "         [-1.0331e-01,  6.1121e-01],\n",
       "         [-4.2999e-01,  9.9632e-02],\n",
       "         [-1.5489e-01,  1.1640e-01],\n",
       "         [ 2.8926e-02,  1.7941e-01],\n",
       "         [ 2.3035e-01,  2.5126e-01],\n",
       "         [-2.2168e-01, -3.0033e-01],\n",
       "         [-1.3960e-01,  4.3716e-01],\n",
       "         [-1.8662e-01,  5.0698e-01],\n",
       "         [-1.0832e-01, -7.7982e-02],\n",
       "         [-2.1516e-01,  1.2913e-01],\n",
       "         [-2.0541e-01, -4.4197e-02],\n",
       "         [-1.1214e-01, -1.3545e-01],\n",
       "         [ 1.1761e-01,  5.5995e-02],\n",
       "         [ 1.3900e-01,  9.9213e-02],\n",
       "         [ 9.9568e-02,  1.1273e-01],\n",
       "         [ 6.1267e-02,  1.6151e-01],\n",
       "         [ 5.0690e-02,  3.9618e-01],\n",
       "         [ 1.7242e-01,  1.2116e-01],\n",
       "         [ 8.5439e-02,  3.4699e-01],\n",
       "         [ 6.2049e-02, -1.0199e-01],\n",
       "         [ 8.0454e-02, -3.2418e-01],\n",
       "         [ 5.4118e-02,  1.4056e-01],\n",
       "         [ 8.1945e-02,  5.0110e-02],\n",
       "         [ 2.8847e-01,  2.3783e-01],\n",
       "         [-6.6531e-02,  1.0848e-02],\n",
       "         [ 1.8290e-01,  3.8800e-02],\n",
       "         [ 8.8050e-02,  1.7738e-01],\n",
       "         [-1.1713e-01, -2.3837e-01],\n",
       "         [-3.4542e-02, -2.7510e-02],\n",
       "         [ 1.3054e-01,  1.2972e-02],\n",
       "         [ 2.3451e-01,  8.0896e-02],\n",
       "         [ 1.7656e-01,  5.1882e-01],\n",
       "         [ 2.9031e-01, -8.7568e-02],\n",
       "         [ 3.2659e-01,  7.1459e-02],\n",
       "         [ 2.5335e-01,  2.1349e-01],\n",
       "         [-1.9288e-02,  1.0122e-02],\n",
       "         [-1.7453e-01, -8.7132e-02],\n",
       "         [-8.6411e-02,  3.4752e-01],\n",
       "         [ 3.7412e-02,  3.7738e-01],\n",
       "         [ 1.4869e-01,  3.8253e-01],\n",
       "         [ 2.0522e-01,  4.6807e-01],\n",
       "         [ 2.7841e-01,  2.8060e-01],\n",
       "         [ 4.5684e-02,  4.6303e-01],\n",
       "         [-2.1255e-01, -1.7855e-01],\n",
       "         [ 4.4518e-03,  2.1844e-01],\n",
       "         [ 1.2134e-01,  2.4395e-01],\n",
       "         [-2.8862e-01,  1.0130e-01],\n",
       "         [-2.6457e-01,  3.4446e-01],\n",
       "         [-2.2972e-01,  5.6276e-01],\n",
       "         [-9.6656e-02,  6.7792e-01],\n",
       "         [-6.0996e-02,  9.1442e-01],\n",
       "         [ 4.1067e-02,  6.2289e-01],\n",
       "         [ 8.2443e-02,  3.3905e-01],\n",
       "         [ 3.7266e-02,  7.7146e-04],\n",
       "         [ 1.3337e-01,  1.8936e-01],\n",
       "         [ 2.2118e-01,  2.6898e-01],\n",
       "         [ 2.0054e-01,  3.0138e-01],\n",
       "         [ 1.7095e-01,  2.6426e-01],\n",
       "         [ 1.1854e-01,  8.3858e-02],\n",
       "         [ 3.1556e-03,  7.9145e-02],\n",
       "         [-4.2056e-02,  2.0226e-01],\n",
       "         [ 2.2120e-01,  5.1720e-02],\n",
       "         [-1.1560e-01, -3.8970e-01],\n",
       "         [ 1.3393e-01,  1.8138e-01],\n",
       "         [ 2.4230e-01,  2.7837e-01],\n",
       "         [ 2.7006e-01,  1.6006e-02],\n",
       "         [ 3.0507e-01,  3.1579e-01],\n",
       "         [ 3.1435e-02, -2.5856e-02],\n",
       "         [ 2.1312e-01,  3.5983e-02],\n",
       "         [-5.9285e-03, -2.3706e-01],\n",
       "         [ 9.9092e-02, -1.0569e-01],\n",
       "         [ 4.3036e-02,  3.5595e-01],\n",
       "         [-3.2149e-01,  9.7367e-02],\n",
       "         [-2.1357e-01,  6.3700e-01],\n",
       "         [ 2.7401e-01,  3.0791e-01],\n",
       "         [ 7.9139e-02,  1.8312e-01],\n",
       "         [ 2.1662e-01,  2.9448e-01],\n",
       "         [ 2.2349e-01,  4.3721e-01],\n",
       "         [-1.5870e-03,  5.8617e-02],\n",
       "         [ 1.0556e-01,  6.6565e-01],\n",
       "         [ 1.5579e-01,  5.4544e-01],\n",
       "         [-5.8069e-02, -8.8961e-02],\n",
       "         [-1.0718e-01,  1.9268e-01],\n",
       "         [ 2.0615e-01,  2.8711e-01],\n",
       "         [ 2.3731e-01,  2.0670e-01],\n",
       "         [ 1.0200e-01,  2.4411e-01],\n",
       "         [-1.3021e-01,  8.6836e-02],\n",
       "         [ 1.1123e-01,  7.0699e-01],\n",
       "         [ 1.1882e-01,  6.3507e-01],\n",
       "         [ 1.5968e-01,  5.6605e-01],\n",
       "         [ 1.3795e-01,  5.2429e-01],\n",
       "         [ 1.0390e-01,  5.0025e-01],\n",
       "         [ 9.2013e-02,  5.3698e-01],\n",
       "         [ 1.0870e-01, -7.1577e-02],\n",
       "         [ 3.4707e-02,  4.1429e-01],\n",
       "         [ 3.3253e-02, -3.2782e-01],\n",
       "         [ 2.7598e-01,  2.2903e-01],\n",
       "         [ 2.8613e-01,  3.5167e-01],\n",
       "         [ 6.5374e-02, -3.4681e-01],\n",
       "         [ 2.1395e-01,  3.5598e-01],\n",
       "         [ 9.0134e-02,  4.4041e-01],\n",
       "         [-9.5893e-02,  4.2066e-01],\n",
       "         [-1.1267e-01,  3.6016e-04],\n",
       "         [-1.4358e-01,  4.1116e-02],\n",
       "         [ 9.4191e-02,  6.3209e-02],\n",
       "         [ 3.1919e-01,  1.7767e-01],\n",
       "         [ 1.4443e-01, -2.6945e-01],\n",
       "         [ 1.2561e-01,  4.9418e-02],\n",
       "         [ 4.2773e-02,  8.6354e-02],\n",
       "         [ 1.3540e-01,  1.1152e-01],\n",
       "         [ 1.3599e-01,  1.0448e-01],\n",
       "         [ 1.1106e-01,  9.6303e-02],\n",
       "         [ 9.4783e-02,  7.0288e-02],\n",
       "         [ 1.0352e-01,  3.7666e-02],\n",
       "         [ 1.2286e-01, -2.4109e-03],\n",
       "         [ 1.4103e-01,  1.3395e-03],\n",
       "         [ 6.9699e-02, -1.8896e-02],\n",
       "         [ 8.2091e-02,  7.1940e-02],\n",
       "         [ 2.2770e-01, -2.3292e-01],\n",
       "         [-1.7776e-01, -6.5674e-01],\n",
       "         [-1.0465e-02,  1.2544e-01],\n",
       "         [ 1.8864e-01,  2.7941e-01],\n",
       "         [ 1.1143e-01,  3.8282e-01],\n",
       "         [ 7.7424e-02,  6.0868e-02],\n",
       "         [ 9.6034e-02, -1.4569e-01],\n",
       "         [ 1.6886e-01,  2.1297e-01],\n",
       "         [-8.2643e-02, -1.7411e-01],\n",
       "         [-1.0881e-02,  2.9962e-01],\n",
       "         [-8.7532e-02, -4.1155e-03],\n",
       "         [-2.0686e-01,  4.9057e-02],\n",
       "         [ 1.2268e-01,  6.4656e-02],\n",
       "         [ 1.7313e-01,  1.6293e-01],\n",
       "         [ 5.0468e-02,  2.1396e-01],\n",
       "         [ 1.3197e-01, -1.3537e-01],\n",
       "         [ 1.4971e-01,  1.8612e-01],\n",
       "         [ 1.1202e-01,  5.0844e-02],\n",
       "         [-1.1466e-01,  6.1197e-02],\n",
       "         [-5.8735e-02,  7.9411e-02],\n",
       "         [ 2.0351e-01,  1.5727e-01],\n",
       "         [ 1.1812e-01,  1.8076e-01],\n",
       "         [ 4.0741e-01,  5.1116e-01],\n",
       "         [ 1.6288e-01,  3.4198e-01],\n",
       "         [ 2.0393e-01,  4.8463e-01],\n",
       "         [ 7.9016e-02,  3.1623e-01],\n",
       "         [ 6.4013e-02,  2.5207e-01],\n",
       "         [ 8.3625e-02,  3.1164e-01],\n",
       "         [ 1.3604e-01,  6.3669e-02],\n",
       "         [ 1.0180e-01,  2.0496e-01],\n",
       "         [ 6.2951e-02,  2.2238e-01],\n",
       "         [ 1.8008e-02,  1.6292e-01],\n",
       "         [ 6.2350e-02,  1.1687e-01],\n",
       "         [-7.3352e-02, -2.2000e-02],\n",
       "         [ 7.0307e-02,  1.8316e-01],\n",
       "         [ 4.9600e-02,  1.2047e-01],\n",
       "         [ 8.8091e-02,  6.4686e-02],\n",
       "         [ 1.7186e-01,  8.2201e-02],\n",
       "         [ 2.5099e-01,  2.3695e-01],\n",
       "         [-1.2500e-02, -8.8694e-02],\n",
       "         [ 6.1255e-02,  3.4781e-01],\n",
       "         [ 1.1925e-01,  1.5651e-01],\n",
       "         [ 7.3421e-02,  2.0542e-01],\n",
       "         [-3.0322e-03,  2.1131e-01],\n",
       "         [ 6.4291e-02,  1.5706e-01],\n",
       "         [ 1.3804e-01,  3.2835e-01],\n",
       "         [ 2.8139e-02, -1.1183e-02],\n",
       "         [ 8.5144e-02,  4.5610e-01],\n",
       "         [ 9.0270e-02,  6.0974e-01],\n",
       "         [-6.4889e-02, -1.8764e-02],\n",
       "         [-1.2032e-01,  2.5151e-01],\n",
       "         [-9.8129e-02,  2.8019e-01],\n",
       "         [-5.4398e-03,  5.7697e-01],\n",
       "         [ 1.5239e-01,  3.6155e-01],\n",
       "         [-5.2059e-02,  4.9302e-02],\n",
       "         [ 7.5327e-02,  3.9195e-01],\n",
       "         [ 1.4413e-01,  4.5303e-01],\n",
       "         [ 2.6556e-01,  6.9154e-01],\n",
       "         [ 2.8987e-01,  1.4171e-01],\n",
       "         [-7.9981e-02,  6.2058e-02],\n",
       "         [-1.3010e-02,  2.8687e-01],\n",
       "         [-8.8272e-02, -1.3086e-01],\n",
       "         [-1.5154e-01,  1.3613e-01],\n",
       "         [ 1.0477e-01,  2.3679e-01],\n",
       "         [ 1.6271e-01,  1.7414e-01],\n",
       "         [ 1.7284e-01, -3.7926e-02],\n",
       "         [ 2.2994e-01, -1.0672e-02],\n",
       "         [ 2.1882e-01,  1.6849e-01],\n",
       "         [ 7.3606e-02,  7.9806e-03],\n",
       "         [ 7.3567e-02,  3.1525e-01],\n",
       "         [ 1.9310e-01,  7.7643e-02],\n",
       "         [ 1.4368e-01,  3.9031e-01],\n",
       "         [ 8.8794e-02,  1.4969e-01],\n",
       "         [-6.2331e-02, -2.8937e-01],\n",
       "         [ 9.7332e-02,  1.0127e-01],\n",
       "         [-4.3796e-04,  1.4264e-01],\n",
       "         [ 1.3716e-02,  8.3602e-02],\n",
       "         [ 1.1087e-01, -7.1258e-02],\n",
       "         [ 2.2061e-01,  1.1835e-01],\n",
       "         [ 2.6272e-01,  3.9132e-01],\n",
       "         [ 9.0447e-02,  5.0202e-02],\n",
       "         [ 1.9683e-01,  3.7918e-01],\n",
       "         [ 1.0287e-01,  3.5772e-01],\n",
       "         [ 1.6986e-01,  3.5515e-01],\n",
       "         [ 1.8705e-01,  6.1923e-01],\n",
       "         [ 1.4018e-01, -1.9630e-02],\n",
       "         [-2.1833e-02,  4.5067e-01],\n",
       "         [-4.9175e-02,  1.6470e-01],\n",
       "         [ 1.1027e-01, -1.9994e-01],\n",
       "         [ 2.9338e-01,  2.1897e-01],\n",
       "         [ 2.8341e-01,  1.9570e-01],\n",
       "         [ 3.3866e-01,  1.6062e-01],\n",
       "         [ 2.1298e-01,  2.1272e-01],\n",
       "         [-2.4507e-01,  1.2163e-01],\n",
       "         [ 6.5251e-02,  4.0498e-01],\n",
       "         [-3.5371e-02,  2.5745e-01],\n",
       "         [-1.2855e-01,  1.5865e-02],\n",
       "         [-3.6544e-01,  5.8060e-01],\n",
       "         [-3.6941e-01,  2.8536e-01],\n",
       "         [ 1.0297e-01,  3.9207e-01],\n",
       "         [ 2.3167e-01,  3.2535e-01],\n",
       "         [ 2.0902e-01,  1.9725e-01],\n",
       "         [ 2.5379e-01,  1.5523e-01],\n",
       "         [ 2.4446e-01,  1.3720e-01],\n",
       "         [ 2.1510e-01,  1.3100e-01],\n",
       "         [ 1.7701e-01,  1.2817e-01],\n",
       "         [ 1.2973e-01,  1.3370e-01],\n",
       "         [ 8.3940e-02,  1.4483e-01],\n",
       "         [ 1.6609e-02,  1.3181e-01],\n",
       "         [-5.1309e-02,  9.8409e-02],\n",
       "         [-8.6527e-02,  1.1758e-01],\n",
       "         [-1.0336e-01,  1.5751e-01],\n",
       "         [-1.0568e-01,  1.6134e-01],\n",
       "         [-9.5119e-02,  1.3980e-01],\n",
       "         [-1.0137e-01,  1.6264e-01],\n",
       "         [-1.0345e-01,  1.8271e-01],\n",
       "         [-1.0506e-01,  1.8889e-01],\n",
       "         [-1.0798e-01,  1.7646e-01],\n",
       "         [-1.0605e-01,  1.9695e-01],\n",
       "         [-9.9078e-02,  2.0970e-01],\n",
       "         [-7.9743e-02,  2.2721e-01],\n",
       "         [-7.0105e-02,  2.5058e-01],\n",
       "         [ 1.4863e-01, -9.7502e-04],\n",
       "         [ 1.4956e-01, -1.9494e-03],\n",
       "         [ 1.5102e-01, -1.6719e-03],\n",
       "         [ 1.5213e-01, -1.5057e-03]]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'LABEL_0', 1: 'LABEL_1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 292, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5188, 0.6169],\n",
       "        [0.5188, 0.6169],\n",
       "        [0.5188, 0.6169],\n",
       "        [0.5188, 0.6169],\n",
       "        [0.5188, 0.6169],\n",
       "        [0.4865, 0.6212],\n",
       "        [0.4928, 0.6190],\n",
       "        [0.4984, 0.6183],\n",
       "        [0.4950, 0.6223],\n",
       "        [0.5005, 0.6186],\n",
       "        [0.4999, 0.6170],\n",
       "        [0.4976, 0.6181],\n",
       "        [0.4936, 0.6206],\n",
       "        [0.4928, 0.6212],\n",
       "        [0.4980, 0.6186],\n",
       "        [0.4982, 0.6161],\n",
       "        [0.5050, 0.6202],\n",
       "        [0.5100, 0.6188],\n",
       "        [0.5180, 0.6018],\n",
       "        [0.5135, 0.5818],\n",
       "        [0.5116, 0.5714],\n",
       "        [0.5184, 0.5639],\n",
       "        [0.5227, 0.5568],\n",
       "        [0.5246, 0.5461],\n",
       "        [0.5310, 0.5466],\n",
       "        [0.5473, 0.5661],\n",
       "        [0.5462, 0.5707],\n",
       "        [0.5135, 0.5762],\n",
       "        [0.4529, 0.4955],\n",
       "        [0.4928, 0.6499],\n",
       "        [0.5164, 0.5299],\n",
       "        [0.5099, 0.5310],\n",
       "        [0.5391, 0.4204],\n",
       "        [0.6019, 0.5347],\n",
       "        [0.4948, 0.4575],\n",
       "        [0.4610, 0.6205],\n",
       "        [0.4405, 0.5906],\n",
       "        [0.4930, 0.4670],\n",
       "        [0.4595, 0.4969],\n",
       "        [0.4731, 0.5715],\n",
       "        [0.5109, 0.5808],\n",
       "        [0.5273, 0.5085],\n",
       "        [0.5182, 0.5510],\n",
       "        [0.4122, 0.5162],\n",
       "        [0.5010, 0.5194],\n",
       "        [0.4704, 0.5384],\n",
       "        [0.4740, 0.6202],\n",
       "        [0.5198, 0.5898],\n",
       "        [0.4742, 0.6482],\n",
       "        [0.3941, 0.5249],\n",
       "        [0.4614, 0.5291],\n",
       "        [0.5072, 0.5447],\n",
       "        [0.5573, 0.5625],\n",
       "        [0.4448, 0.4255],\n",
       "        [0.4652, 0.6076],\n",
       "        [0.4535, 0.6241],\n",
       "        [0.4729, 0.4805],\n",
       "        [0.4464, 0.5322],\n",
       "        [0.4488, 0.4890],\n",
       "        [0.4720, 0.4662],\n",
       "        [0.5294, 0.5140],\n",
       "        [0.5347, 0.5248],\n",
       "        [0.5249, 0.5282],\n",
       "        [0.5153, 0.5403],\n",
       "        [0.5127, 0.5978],\n",
       "        [0.5430, 0.5303],\n",
       "        [0.5213, 0.5859],\n",
       "        [0.5155, 0.4745],\n",
       "        [0.5201, 0.4197],\n",
       "        [0.5135, 0.5351],\n",
       "        [0.5205, 0.5125],\n",
       "        [0.5716, 0.5592],\n",
       "        [0.4834, 0.5027],\n",
       "        [0.5456, 0.5097],\n",
       "        [0.5220, 0.5442],\n",
       "        [0.4708, 0.4407],\n",
       "        [0.4914, 0.4931],\n",
       "        [0.5326, 0.5032],\n",
       "        [0.5584, 0.5202],\n",
       "        [0.5440, 0.6269],\n",
       "        [0.5721, 0.4781],\n",
       "        [0.5809, 0.5179],\n",
       "        [0.5630, 0.5532],\n",
       "        [0.4952, 0.5025],\n",
       "        [0.4565, 0.4782],\n",
       "        [0.4784, 0.5860],\n",
       "        [0.5094, 0.5932],\n",
       "        [0.5371, 0.5945],\n",
       "        [0.5511, 0.6149],\n",
       "        [0.5692, 0.5697],\n",
       "        [0.5114, 0.6137],\n",
       "        [0.4471, 0.4555],\n",
       "        [0.5011, 0.5544],\n",
       "        [0.5303, 0.5607],\n",
       "        [0.4283, 0.5253],\n",
       "        [0.4342, 0.5853],\n",
       "        [0.4428, 0.6371],\n",
       "        [0.4759, 0.6633],\n",
       "        [0.4848, 0.7139],\n",
       "        [0.5103, 0.6509],\n",
       "        [0.5206, 0.5840],\n",
       "        [0.5093, 0.5002],\n",
       "        [0.5333, 0.5472],\n",
       "        [0.5551, 0.5668],\n",
       "        [0.5500, 0.5748],\n",
       "        [0.5426, 0.5657],\n",
       "        [0.5296, 0.5210],\n",
       "        [0.5008, 0.5198],\n",
       "        [0.4895, 0.5504],\n",
       "        [0.5551, 0.5129],\n",
       "        [0.4711, 0.4038],\n",
       "        [0.5334, 0.5452],\n",
       "        [0.5603, 0.5691],\n",
       "        [0.5671, 0.5040],\n",
       "        [0.5757, 0.5783],\n",
       "        [0.5079, 0.4935],\n",
       "        [0.5531, 0.5090],\n",
       "        [0.4985, 0.4410],\n",
       "        [0.5248, 0.4736],\n",
       "        [0.5108, 0.5881],\n",
       "        [0.4203, 0.5243],\n",
       "        [0.4468, 0.6541],\n",
       "        [0.5681, 0.5764],\n",
       "        [0.5198, 0.5457],\n",
       "        [0.5539, 0.5731],\n",
       "        [0.5556, 0.6076],\n",
       "        [0.4996, 0.5147],\n",
       "        [0.5264, 0.6605],\n",
       "        [0.5389, 0.6331],\n",
       "        [0.4855, 0.4778],\n",
       "        [0.4732, 0.5480],\n",
       "        [0.5514, 0.5713],\n",
       "        [0.5590, 0.5515],\n",
       "        [0.5255, 0.5607],\n",
       "        [0.4675, 0.5217],\n",
       "        [0.5278, 0.6697],\n",
       "        [0.5297, 0.6536],\n",
       "        [0.5398, 0.6379],\n",
       "        [0.5344, 0.6281],\n",
       "        [0.5260, 0.6225],\n",
       "        [0.5230, 0.6311],\n",
       "        [0.5271, 0.4821],\n",
       "        [0.5087, 0.6021],\n",
       "        [0.5083, 0.4188],\n",
       "        [0.5686, 0.5570],\n",
       "        [0.5710, 0.5870],\n",
       "        [0.5163, 0.4142],\n",
       "        [0.5533, 0.5881],\n",
       "        [0.5225, 0.6084],\n",
       "        [0.4760, 0.6036],\n",
       "        [0.4719, 0.5001],\n",
       "        [0.4642, 0.5103],\n",
       "        [0.5235, 0.5158],\n",
       "        [0.5791, 0.5443],\n",
       "        [0.5360, 0.4330],\n",
       "        [0.5314, 0.5124],\n",
       "        [0.5107, 0.5216],\n",
       "        [0.5338, 0.5279],\n",
       "        [0.5339, 0.5261],\n",
       "        [0.5277, 0.5241],\n",
       "        [0.5237, 0.5176],\n",
       "        [0.5259, 0.5094],\n",
       "        [0.5307, 0.4994],\n",
       "        [0.5352, 0.5003],\n",
       "        [0.5174, 0.4953],\n",
       "        [0.5205, 0.5180],\n",
       "        [0.5567, 0.4420],\n",
       "        [0.4557, 0.3415],\n",
       "        [0.4974, 0.5313],\n",
       "        [0.5470, 0.5694],\n",
       "        [0.5278, 0.5946],\n",
       "        [0.5193, 0.5152],\n",
       "        [0.5240, 0.4636],\n",
       "        [0.5421, 0.5530],\n",
       "        [0.4794, 0.4566],\n",
       "        [0.4973, 0.5744],\n",
       "        [0.4781, 0.4990],\n",
       "        [0.4485, 0.5123],\n",
       "        [0.5306, 0.5162],\n",
       "        [0.5432, 0.5406],\n",
       "        [0.5126, 0.5533],\n",
       "        [0.5329, 0.4662],\n",
       "        [0.5374, 0.5464],\n",
       "        [0.5280, 0.5127],\n",
       "        [0.4714, 0.5153],\n",
       "        [0.4853, 0.5198],\n",
       "        [0.5507, 0.5392],\n",
       "        [0.5295, 0.5451],\n",
       "        [0.6005, 0.6251],\n",
       "        [0.5406, 0.5847],\n",
       "        [0.5508, 0.6188],\n",
       "        [0.5197, 0.5784],\n",
       "        [0.5160, 0.5627],\n",
       "        [0.5209, 0.5773],\n",
       "        [0.5340, 0.5159],\n",
       "        [0.5254, 0.5511],\n",
       "        [0.5157, 0.5554],\n",
       "        [0.5045, 0.5406],\n",
       "        [0.5156, 0.5292],\n",
       "        [0.4817, 0.4945],\n",
       "        [0.5176, 0.5457],\n",
       "        [0.5124, 0.5301],\n",
       "        [0.5220, 0.5162],\n",
       "        [0.5429, 0.5205],\n",
       "        [0.5624, 0.5590],\n",
       "        [0.4969, 0.4778],\n",
       "        [0.5153, 0.5861],\n",
       "        [0.5298, 0.5390],\n",
       "        [0.5183, 0.5512],\n",
       "        [0.4992, 0.5526],\n",
       "        [0.5161, 0.5392],\n",
       "        [0.5345, 0.5814],\n",
       "        [0.5070, 0.4972],\n",
       "        [0.5213, 0.6121],\n",
       "        [0.5226, 0.6479],\n",
       "        [0.4838, 0.4953],\n",
       "        [0.4700, 0.5625],\n",
       "        [0.4755, 0.5696],\n",
       "        [0.4986, 0.6404],\n",
       "        [0.5380, 0.5894],\n",
       "        [0.4870, 0.5123],\n",
       "        [0.5188, 0.5968],\n",
       "        [0.5360, 0.6114],\n",
       "        [0.5660, 0.6663],\n",
       "        [0.5720, 0.5354],\n",
       "        [0.4800, 0.5155],\n",
       "        [0.4967, 0.5712],\n",
       "        [0.4779, 0.4673],\n",
       "        [0.4622, 0.5340],\n",
       "        [0.5262, 0.5589],\n",
       "        [0.5406, 0.5434],\n",
       "        [0.5431, 0.4905],\n",
       "        [0.5572, 0.4973],\n",
       "        [0.5545, 0.5420],\n",
       "        [0.5184, 0.5020],\n",
       "        [0.5184, 0.5782],\n",
       "        [0.5481, 0.5194],\n",
       "        [0.5359, 0.5964],\n",
       "        [0.5222, 0.5374],\n",
       "        [0.4844, 0.4282],\n",
       "        [0.5243, 0.5253],\n",
       "        [0.4999, 0.5356],\n",
       "        [0.5034, 0.5209],\n",
       "        [0.5277, 0.4822],\n",
       "        [0.5549, 0.5296],\n",
       "        [0.5653, 0.5966],\n",
       "        [0.5226, 0.5125],\n",
       "        [0.5490, 0.5937],\n",
       "        [0.5257, 0.5885],\n",
       "        [0.5424, 0.5879],\n",
       "        [0.5466, 0.6500],\n",
       "        [0.5350, 0.4951],\n",
       "        [0.4945, 0.6108],\n",
       "        [0.4877, 0.5411],\n",
       "        [0.5275, 0.4502],\n",
       "        [0.5728, 0.5545],\n",
       "        [0.5704, 0.5488],\n",
       "        [0.5839, 0.5401],\n",
       "        [0.5530, 0.5530],\n",
       "        [0.4390, 0.5304],\n",
       "        [0.5163, 0.5999],\n",
       "        [0.4912, 0.5640],\n",
       "        [0.4679, 0.5040],\n",
       "        [0.4096, 0.6412],\n",
       "        [0.4087, 0.5709],\n",
       "        [0.5257, 0.5968],\n",
       "        [0.5577, 0.5806],\n",
       "        [0.5521, 0.5492],\n",
       "        [0.5631, 0.5387],\n",
       "        [0.5608, 0.5342],\n",
       "        [0.5536, 0.5327],\n",
       "        [0.5441, 0.5320],\n",
       "        [0.5324, 0.5334],\n",
       "        [0.5210, 0.5361],\n",
       "        [0.5042, 0.5329],\n",
       "        [0.4872, 0.5246],\n",
       "        [0.4784, 0.5294],\n",
       "        [0.4742, 0.5393],\n",
       "        [0.4736, 0.5402],\n",
       "        [0.4762, 0.5349],\n",
       "        [0.4747, 0.5406],\n",
       "        [0.4742, 0.5456],\n",
       "        [0.4738, 0.5471],\n",
       "        [0.4730, 0.5440],\n",
       "        [0.4735, 0.5491],\n",
       "        [0.4753, 0.5522],\n",
       "        [0.4801, 0.5566],\n",
       "        [0.4825, 0.5623],\n",
       "        [0.5371, 0.4998],\n",
       "        [0.5373, 0.4995],\n",
       "        [0.5377, 0.4996],\n",
       "        [0.5380, 0.4996]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels is a one-hot array of shape (num_frames, num_speakers)\n",
    "probabilities = torch.sigmoid(outputs.logits[0])\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (probabilities > 0.5).long()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
