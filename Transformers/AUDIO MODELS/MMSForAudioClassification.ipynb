{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2ForSequenceClassification, AutoFeatureExtractor\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"facebook/mms-lid-126\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/ImageBind#usage\n",
    "\n",
    "For windows users, you might need to install librosa and soundfile for reading/writing audio files. (Thanks @congyue1977)\n",
    "\n",
    "`pip install soundfile librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
       "    num_rows: 73\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "dataset = dataset.sort(\"id\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'C:/Users/Administrator/.cache/huggingface/datasets/downloads/extracted/b49df5cb4e26d70a35c542fbe0eadc8bfee0f971809886d2131859668faeba1c/dev_clean/1272/128104\\\\1272-128104-0000.flac',\n",
       " 'audio': {'path': 'C:/Users/Administrator/.cache/huggingface/datasets/downloads/extracted/b49df5cb4e26d70a35c542fbe0eadc8bfee0f971809886d2131859668faeba1c/dev_clean/1272/128104\\\\1272-128104-0000.flac',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
       "         0.0010376 ]),\n",
       "  'sampling_rate': 16000},\n",
       " 'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL',\n",
       " 'speaker_id': 1272,\n",
       " 'chapter_id': 128104,\n",
       " 'id': '1272-128104-0000'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
       "        0.0010376 ]),\n",
       " array([-1.52587891e-04, -9.15527344e-05, -1.83105469e-04, ...,\n",
       "         9.76562500e-04,  9.46044922e-04, -4.88281250e-04])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get multi array\n",
    "[d[\"array\"] for d in dataset[:2][\"audio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL',\n",
       " \"NOR IS MISTER QUILTER'S MANNER LESS INTERESTING THAN HIS MATTER\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get multi text\n",
    "[d for d in dataset[:2][\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878a94c9e03b4347872232f0517da9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor: AutoFeatureExtractor = AutoFeatureExtractor.from_pretrained(version)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[ 0.0386,  0.0337,  0.0322,  ...,  0.0070,  0.0095,  0.0169],\n",
       "        [-0.0015, -0.0008, -0.0019,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.int32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = feature_extractor(\n",
    "    [d[\"array\"] for d in dataset[:2][\"audio\"]],\n",
    "    sampling_rate=sampling_rate,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device, torch.float16)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 93680])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_values\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wav2Vec2ForSequenceClassification(分辨语言种类)\n",
    "\n",
    "Different LID models are available based on the number of languages they can recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eb41219c4d44648a784de9eddd0688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForSequenceClassification(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1280, bias=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1280, 1280, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (adapter_layer): Wav2Vec2AttnAdapterLayer(\n",
       "            (norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (linear_1): Linear(in_features=1280, out_features=16, bias=True)\n",
       "            (act_fn): ReLU()\n",
       "            (linear_2): Linear(in_features=16, out_features=1280, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projector): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=126, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: Wav2Vec2ForSequenceClassification = Wav2Vec2ForSequenceClassification.from_pretrained(version, torch_dtype=torch.float16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 6.3095e-01,  5.6210e-01,  1.1455e+01,  4.6605e+00,  2.0735e+00,\n",
       "         -1.7886e+00,  2.5402e-01,  1.3036e+00, -1.4132e+00, -1.0144e+00,\n",
       "         -2.1347e+00,  8.1125e-01, -1.2697e+00,  4.8693e-01,  4.3894e-02,\n",
       "         -9.0640e-01, -1.4628e-01, -2.1953e+00,  8.0087e-01, -1.2776e+00,\n",
       "          1.2712e+00, -2.1888e-01,  2.4856e-01, -2.3980e+00, -3.3244e-01,\n",
       "         -5.9368e-01, -1.3560e+00,  3.4993e-01, -1.4715e+00, -1.1132e+00,\n",
       "         -2.2107e+00, -8.6330e-02, -2.7320e+00, -4.6908e-01,  3.4111e-01,\n",
       "          8.3798e-01, -2.7987e+00, -1.6982e+00,  2.0136e-02, -6.3702e-01,\n",
       "          1.7377e+00, -1.9903e-01,  1.2074e-01,  7.2755e-01, -6.1422e-01,\n",
       "         -4.7519e-01, -2.1832e+00, -1.5885e+00,  1.6448e+00,  1.3297e+00,\n",
       "          1.3466e+00,  3.1740e+00, -9.3507e-01,  3.1203e-01,  1.3561e+00,\n",
       "          2.4167e+00, -1.8261e-01, -1.1498e+00,  7.0182e-01, -9.3038e-01,\n",
       "         -1.8628e+00,  4.6539e+00, -9.2118e-01,  1.4500e+00, -2.4243e+00,\n",
       "         -1.6947e+00, -1.5209e+00, -9.6084e-01, -6.8008e-01, -1.5235e+00,\n",
       "          8.2105e-01, -2.2703e+00, -1.6607e+00, -2.5639e-01, -1.1139e+00,\n",
       "         -3.2616e+00, -9.5500e-01, -1.6776e+00,  1.5392e+00,  6.6666e-01,\n",
       "         -1.3092e+00, -1.8192e+00,  5.0085e-01, -4.3142e-01, -1.5456e+00,\n",
       "          5.1788e-01, -1.1086e+00, -2.2766e+00, -2.1420e-01, -2.1902e+00,\n",
       "          5.0977e-01,  6.6917e-01, -1.5110e-01, -2.3660e+00,  6.9317e-01,\n",
       "         -1.4746e-01, -1.2529e+00, -1.2328e+00, -9.7913e-01,  1.2032e+00,\n",
       "          6.8563e-01,  1.8974e+00,  6.9472e-01,  7.9676e-02, -7.7759e-01,\n",
       "         -3.4713e-02, -2.6871e+00, -1.5519e+00, -3.9116e-01, -2.6262e+00,\n",
       "          2.7888e+00, -2.1034e+00, -1.7630e+00, -2.0563e+00,  1.7577e+00,\n",
       "         -2.5987e-01, -1.9188e+00, -7.4699e-01, -1.0907e+00,  2.8862e-02,\n",
       "          9.1536e-01, -1.8944e+00, -5.1767e-01, -4.2618e-01,  9.1762e-01,\n",
       "          5.6687e-01],\n",
       "        [ 7.8589e-01,  1.2938e+00,  1.2341e+01,  4.8396e+00,  1.3167e+00,\n",
       "         -2.2832e+00,  2.4000e-01, -9.0399e-02, -4.5508e-01, -1.9964e+00,\n",
       "         -2.4413e+00,  3.5519e-01, -2.3395e+00,  1.3033e+00,  6.9389e-01,\n",
       "         -8.5295e-01, -2.6635e-03, -2.4284e+00,  5.7707e-01, -1.1783e+00,\n",
       "          8.4686e-01, -8.1766e-02,  9.1626e-01, -2.7056e+00, -5.8931e-01,\n",
       "         -7.6612e-01, -1.4029e+00,  2.3832e-01, -9.1772e-01, -6.6421e-01,\n",
       "         -1.8193e+00,  8.8469e-01, -2.5616e+00,  8.7414e-01,  3.2376e-01,\n",
       "         -2.0832e-01, -3.0206e+00, -8.5069e-01,  5.6358e-01, -1.2561e+00,\n",
       "          1.6699e+00, -5.7222e-01,  4.8531e-02, -5.3311e-02, -1.2038e+00,\n",
       "          3.1030e-01, -1.7178e+00,  4.5527e-01,  2.2202e+00,  1.2224e+00,\n",
       "          1.2557e+00,  3.7554e+00, -1.8596e+00,  7.4223e-01,  1.3819e+00,\n",
       "          2.5061e+00, -3.4736e-01, -1.3056e+00,  1.1819e+00, -1.2866e+00,\n",
       "         -2.4784e+00,  3.6683e+00, -5.2684e-01,  5.7223e-01, -1.8240e+00,\n",
       "         -1.0513e+00, -1.7182e+00, -1.9677e+00, -1.1796e-01, -1.9979e+00,\n",
       "          1.2763e+00, -2.9388e+00, -1.7282e+00, -3.3517e-01, -1.1959e+00,\n",
       "         -3.1514e+00, -5.4477e-01, -1.7328e+00,  1.5199e+00,  2.2135e-01,\n",
       "         -3.5854e-01, -8.5869e-01,  3.2262e-01, -6.5692e-01, -1.5945e+00,\n",
       "          1.5913e+00, -1.0779e+00, -2.4479e+00, -1.0716e+00, -2.2123e+00,\n",
       "          3.7509e-01, -4.9298e-01, -8.9774e-01, -1.7080e+00,  1.7723e+00,\n",
       "         -7.6502e-01, -3.1243e-01, -1.6450e+00, -7.0905e-01,  1.4400e+00,\n",
       "          1.1180e+00,  1.5582e+00,  1.2151e+00, -2.8844e-01, -7.5152e-01,\n",
       "          3.5427e-01, -2.1969e+00, -1.6359e+00, -7.1554e-01, -2.0840e+00,\n",
       "          2.2352e+00, -2.0376e+00, -1.4871e+00, -2.3678e+00,  1.9560e+00,\n",
       "          2.2709e-01, -1.6924e+00, -3.8192e-02,  2.8713e-02,  3.6694e-01,\n",
       "          2.8496e+00, -2.3868e+00,  3.8368e-01, -1.4174e-02,  2.6749e+00,\n",
       "          3.4431e-01]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 126])\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_ids = logits.argmax(dim=-1)\n",
    "predicted_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ara',\n",
       " 1: 'cmn',\n",
       " 2: 'eng',\n",
       " 3: 'spa',\n",
       " 4: 'fra',\n",
       " 5: 'mlg',\n",
       " 6: 'swe',\n",
       " 7: 'por',\n",
       " 8: 'vie',\n",
       " 9: 'ful',\n",
       " 10: 'sun',\n",
       " 11: 'asm',\n",
       " 12: 'ben',\n",
       " 13: 'zlm',\n",
       " 14: 'kor',\n",
       " 15: 'ind',\n",
       " 16: 'hin',\n",
       " 17: 'tuk',\n",
       " 18: 'urd',\n",
       " 19: 'aze',\n",
       " 20: 'slv',\n",
       " 21: 'mon',\n",
       " 22: 'hau',\n",
       " 23: 'tel',\n",
       " 24: 'swh',\n",
       " 25: 'bod',\n",
       " 26: 'rus',\n",
       " 27: 'tur',\n",
       " 28: 'heb',\n",
       " 29: 'mar',\n",
       " 30: 'som',\n",
       " 31: 'tgl',\n",
       " 32: 'tat',\n",
       " 33: 'tha',\n",
       " 34: 'cat',\n",
       " 35: 'ron',\n",
       " 36: 'mal',\n",
       " 37: 'bel',\n",
       " 38: 'pol',\n",
       " 39: 'yor',\n",
       " 40: 'nld',\n",
       " 41: 'bul',\n",
       " 42: 'hat',\n",
       " 43: 'afr',\n",
       " 44: 'isl',\n",
       " 45: 'amh',\n",
       " 46: 'tam',\n",
       " 47: 'hun',\n",
       " 48: 'hrv',\n",
       " 49: 'lit',\n",
       " 50: 'cym',\n",
       " 51: 'fas',\n",
       " 52: 'mkd',\n",
       " 53: 'ell',\n",
       " 54: 'bos',\n",
       " 55: 'deu',\n",
       " 56: 'sqi',\n",
       " 57: 'jav',\n",
       " 58: 'nob',\n",
       " 59: 'uzb',\n",
       " 60: 'snd',\n",
       " 61: 'lat',\n",
       " 62: 'nya',\n",
       " 63: 'grn',\n",
       " 64: 'mya',\n",
       " 65: 'orm',\n",
       " 66: 'lin',\n",
       " 67: 'hye',\n",
       " 68: 'yue',\n",
       " 69: 'pan',\n",
       " 70: 'jpn',\n",
       " 71: 'kaz',\n",
       " 72: 'npi',\n",
       " 73: 'kat',\n",
       " 74: 'guj',\n",
       " 75: 'kan',\n",
       " 76: 'tgk',\n",
       " 77: 'ukr',\n",
       " 78: 'ces',\n",
       " 79: 'lav',\n",
       " 80: 'bak',\n",
       " 81: 'khm',\n",
       " 82: 'fao',\n",
       " 83: 'glg',\n",
       " 84: 'ltz',\n",
       " 85: 'lao',\n",
       " 86: 'mlt',\n",
       " 87: 'sin',\n",
       " 88: 'sna',\n",
       " 89: 'ita',\n",
       " 90: 'srp',\n",
       " 91: 'mri',\n",
       " 92: 'nno',\n",
       " 93: 'pus',\n",
       " 94: 'eus',\n",
       " 95: 'ory',\n",
       " 96: 'lug',\n",
       " 97: 'bre',\n",
       " 98: 'luo',\n",
       " 99: 'slk',\n",
       " 100: 'fin',\n",
       " 101: 'dan',\n",
       " 102: 'yid',\n",
       " 103: 'est',\n",
       " 104: 'ceb',\n",
       " 105: 'war',\n",
       " 106: 'san',\n",
       " 107: 'kir',\n",
       " 108: 'oci',\n",
       " 109: 'wol',\n",
       " 110: 'haw',\n",
       " 111: 'kam',\n",
       " 112: 'umb',\n",
       " 113: 'xho',\n",
       " 114: 'epo',\n",
       " 115: 'zul',\n",
       " 116: 'ibo',\n",
       " 117: 'abk',\n",
       " 118: 'ckb',\n",
       " 119: 'nso',\n",
       " 120: 'gle',\n",
       " 121: 'kea',\n",
       " 122: 'ast',\n",
       " 123: 'sco',\n",
       " 124: 'glv',\n",
       " 125: 'ina'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n",
      "eng\n"
     ]
    }
   ],
   "source": [
    "print(model.config.id2label[predicted_class_ids[0].item()])\n",
    "print(model.config.id2label[predicted_class_ids[1].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
