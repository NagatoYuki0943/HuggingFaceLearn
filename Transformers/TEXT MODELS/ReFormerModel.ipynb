{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/model_doc/reformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ReformerModel, ReformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"google/reformer-crime-and-punishment\"\n",
    "sequence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformerTokenizer(name_or_path='google/reformer-crime-and-punishment', vocab_size=320, model_max_length=524288, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer: ReformerTokenizer = ReformerTokenizer.from_pretrained(version)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'length', 'attention_mask'])\n",
      "tensor([[140, 243, 264, 134,  17, 267,  77, 263,  22, 262, 297, 258, 304, 177,\n",
      "         279, 266,  14,  89,  13,  35, 261, 299, 272, 137, 275, 278],\n",
      "        [140, 243, 264, 134,  17, 267,  77, 263,  22, 262, 297, 258, 304, 177,\n",
      "         279, 266,  14,  89,  13,  35, 261, 299, 272, 137, 275, 278]],\n",
      "       device='cuda:0')\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')\n",
      "tensor([26, 26], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [sequence] * 2,                     # 句子batch\n",
    "    truncation = True,                  # 超出max_length截断处理\n",
    "    # padding = True,                   # 填充方式选择 [True, 'longest', 'max_length', 'do_not_pad']\n",
    "    # max_length = max_length,          # 最长长度,不设置默认为模型最大长度\n",
    "    add_special_tokens = True,          # text添加特殊key\n",
    "    return_length = True,               # 返回有效长度\n",
    "    return_overflowing_tokens = False,  # 返回所有的文本片段（由于文本比较长，默认情况下超过预设截断长度的token会被丢失。如果设置了return_overflowing_tokens=True则会返回所有的token片段）。\n",
    "    return_tensors = \"pt\"               # 返回数据格式 np pt tf jax\n",
    ").to(device, torch.float16)    # https://github.com/huggingface/transformers/issues/16359\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs[\"input_ids\"])\n",
    "print(inputs[\"attention_mask\"]) # 对应是否是文字\n",
    "print(inputs[\"length\"])         # 对应有效文字长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[140, 243, 264, 134,  17, 267,  77, 263,  22, 262, 297, 258, 304, 177,\n",
      "         279, 266,  14,  89,  13,  35, 261, 299, 272, 137, 275, 278],\n",
      "        [140, 243, 264, 134,  17, 267,  77, 263,  22, 262, 297, 258, 304, 177,\n",
      "         279, 266,  14,  89,  13,  35, 261, 299, 272, 137, 275, 278]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReformerModel\n",
    "\n",
    "The bare Reformer Model transformer outputting raw hidden-stateswithout any specific head on top. Reformer was proposed in Reformer: The Efficient Transformer by Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformerModel(\n",
       "  (embeddings): ReformerEmbeddings(\n",
       "    (word_embeddings): Embedding(320, 256)\n",
       "    (position_embeddings): AxialPositionEmbeddings(\n",
       "      (weights): ParameterList(\n",
       "          (0): Parameter containing: [torch.float32 of size 512x1x64 (cuda:0)]\n",
       "          (1): Parameter containing: [torch.float32 of size 1x1024x192 (cuda:0)]\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): ReformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): ReformerLayer(\n",
       "        (attention): ReformerAttention(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (self_attention): LocalSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (key): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=128, bias=False)\n",
       "          )\n",
       "          (output): ReformerSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (feed_forward): ChunkReformerFeedForward(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dense): ReformerFeedForwardDense(\n",
       "            (act_fn): ReLU()\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): ReformerFeedForwardOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ReformerLayer(\n",
       "        (attention): ReformerAttention(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (self_attention): LSHSelfAttention(\n",
       "            (query_key): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=128, bias=False)\n",
       "          )\n",
       "          (output): ReformerSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (feed_forward): ChunkReformerFeedForward(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dense): ReformerFeedForwardDense(\n",
       "            (act_fn): ReLU()\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): ReformerFeedForwardOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ReformerLayer(\n",
       "        (attention): ReformerAttention(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (self_attention): LocalSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (key): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=128, bias=False)\n",
       "          )\n",
       "          (output): ReformerSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (feed_forward): ChunkReformerFeedForward(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dense): ReformerFeedForwardDense(\n",
       "            (act_fn): ReLU()\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): ReformerFeedForwardOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ReformerLayer(\n",
       "        (attention): ReformerAttention(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (self_attention): LSHSelfAttention(\n",
       "            (query_key): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=128, bias=False)\n",
       "          )\n",
       "          (output): ReformerSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (feed_forward): ChunkReformerFeedForward(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dense): ReformerFeedForwardDense(\n",
       "            (act_fn): ReLU()\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): ReformerFeedForwardOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ReformerLayer(\n",
       "        (attention): ReformerAttention(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (self_attention): LocalSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (key): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=128, bias=False)\n",
       "          )\n",
       "          (output): ReformerSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (feed_forward): ChunkReformerFeedForward(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dense): ReformerFeedForwardDense(\n",
       "            (act_fn): ReLU()\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): ReformerFeedForwardOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ReformerLayer(\n",
       "        (attention): ReformerAttention(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (self_attention): LSHSelfAttention(\n",
       "            (query_key): Linear(in_features=256, out_features=128, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=128, bias=False)\n",
       "          )\n",
       "          (output): ReformerSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (feed_forward): ChunkReformerFeedForward(\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dense): ReformerFeedForwardDense(\n",
       "            (act_fn): ReLU()\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "          )\n",
       "          (output): ReformerFeedForwardOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: ReformerModel = ReformerModel.from_pretrained(version, torch_dtype=torch.float16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformerModelOutput(last_hidden_state=tensor([[[-0.1733,  0.2357,  0.3284,  ...,  0.6766,  0.4675,  0.1250],\n",
       "         [-0.1559,  0.2170,  0.7596,  ...,  0.2714,  0.6945,  0.2284],\n",
       "         [ 0.3256,  0.7184,  0.3327,  ..., -0.7029,  0.2363,  0.1679],\n",
       "         ...,\n",
       "         [-0.7055,  0.1181, -0.6565,  ...,  3.2471,  1.2641, -0.4303],\n",
       "         [ 0.8279, -0.5580,  0.0164,  ...,  0.3295, -1.9403, -0.1466],\n",
       "         [ 0.6393,  0.2772,  0.0120,  ..., -0.1929,  0.4733, -3.3677]],\n",
       "\n",
       "        [[-0.1733,  0.2357,  0.3284,  ...,  0.6766,  0.4675,  0.1250],\n",
       "         [-0.1559,  0.2170,  0.7596,  ...,  0.2714,  0.6945,  0.2284],\n",
       "         [ 0.3256,  0.7184,  0.3327,  ..., -0.7029,  0.2363,  0.1679],\n",
       "         ...,\n",
       "         [-0.7055,  0.1181, -0.6565,  ...,  3.2471,  1.2641, -0.4303],\n",
       "         [ 0.8279, -0.5580,  0.0164,  ...,  0.3295, -1.9403, -0.1466],\n",
       "         [ 0.6393,  0.2772,  0.0120,  ..., -0.1929,  0.4733, -3.3677]]],\n",
       "       device='cuda:0'), past_buckets_states=[(None, tensor([[[ 0.1464,  0.4015, -0.2822,  ...,  0.5889, -0.0777,  0.4136],\n",
       "         [ 0.1519,  0.0989, -0.0216,  ...,  0.2777,  0.1037,  0.6099],\n",
       "         [-0.2996, -0.0791,  0.4266,  ..., -0.8847, -0.3866,  0.8433],\n",
       "         ...,\n",
       "         [-0.8859,  0.2220, -0.2187,  ...,  0.6535,  0.0087, -0.3495],\n",
       "         [-0.5077, -0.1183, -0.5767,  ..., -1.2760, -0.4664,  0.3468],\n",
       "         [-0.5877,  1.0855, -0.3837,  ..., -0.5742, -0.4631, -0.7215]],\n",
       "\n",
       "        [[ 0.1464,  0.4015, -0.2822,  ...,  0.5889, -0.0777,  0.4136],\n",
       "         [ 0.1519,  0.0989, -0.0216,  ...,  0.2777,  0.1037,  0.6099],\n",
       "         [-0.2996, -0.0791,  0.4266,  ..., -0.8847, -0.3866,  0.8433],\n",
       "         ...,\n",
       "         [-0.8859,  0.2220, -0.2187,  ...,  0.6535,  0.0087, -0.3495],\n",
       "         [-0.5077, -0.1183, -0.5767,  ..., -1.2760, -0.4664,  0.3468],\n",
       "         [-0.5877,  1.0855, -0.3837,  ..., -0.5742, -0.4631, -0.7215]]],\n",
       "       device='cuda:0')), (None, tensor([[[ 0.4869,  0.1473, -0.0386,  ...,  0.4913,  0.1780,  0.4248],\n",
       "         [ 0.4478,  0.0603,  0.0959,  ...,  0.0459,  0.4324,  0.2654],\n",
       "         [ 0.3228,  0.1587, -0.2426,  ..., -0.6792,  0.7819,  0.4176],\n",
       "         ...,\n",
       "         [-0.1165, -0.0866,  0.0534,  ...,  0.5114,  0.2030,  0.0111],\n",
       "         [-0.0797, -0.2399, -0.4013,  ..., -0.5075, -0.3453,  0.0632],\n",
       "         [-0.4655,  0.5892, -0.2590,  ..., -0.3276, -0.2302, -0.5278]],\n",
       "\n",
       "        [[ 0.4869,  0.1473, -0.0386,  ...,  0.4913,  0.1780,  0.4248],\n",
       "         [ 0.4478,  0.0603,  0.0959,  ...,  0.0459,  0.4324,  0.2654],\n",
       "         [ 0.3228,  0.1587, -0.2426,  ..., -0.6792,  0.7819,  0.4176],\n",
       "         ...,\n",
       "         [-0.1165, -0.0866,  0.0534,  ...,  0.5114,  0.2030,  0.0111],\n",
       "         [-0.0797, -0.2399, -0.4013,  ..., -0.5075, -0.3453,  0.0632],\n",
       "         [-0.4655,  0.5892, -0.2590,  ..., -0.3276, -0.2302, -0.5278]]],\n",
       "       device='cuda:0')), (None, tensor([[[ 0.7578,  0.1466,  0.4369,  ...,  0.2922,  0.1477,  0.3717],\n",
       "         [ 0.4341, -0.0676, -0.4248,  ..., -0.5093,  0.7699,  0.2353],\n",
       "         [ 0.2573,  0.1376, -1.0701,  ..., -0.7180,  0.6447,  0.7833],\n",
       "         ...,\n",
       "         [-0.4104, -0.1811, -0.1661,  ...,  1.0087,  0.4840,  0.0814],\n",
       "         [-0.8407, -0.1876, -1.1465,  ..., -0.5352, -0.8728, -0.0808],\n",
       "         [-0.2193,  0.9366, -0.8513,  ..., -0.2393, -0.6523, -1.1628]],\n",
       "\n",
       "        [[ 0.7578,  0.1466,  0.4369,  ...,  0.2922,  0.1477,  0.3717],\n",
       "         [ 0.4341, -0.0676, -0.4248,  ..., -0.5093,  0.7699,  0.2353],\n",
       "         [ 0.2573,  0.1376, -1.0701,  ..., -0.7180,  0.6447,  0.7833],\n",
       "         ...,\n",
       "         [-0.4104, -0.1811, -0.1661,  ...,  1.0087,  0.4840,  0.0814],\n",
       "         [-0.8407, -0.1876, -1.1465,  ..., -0.5352, -0.8728, -0.0808],\n",
       "         [-0.2193,  0.9366, -0.8513,  ..., -0.2393, -0.6523, -1.1628]]],\n",
       "       device='cuda:0')), (None, tensor([[[ 0.4613,  0.3319,  0.1881,  ...,  0.1721,  0.4894,  0.2425],\n",
       "         [ 0.0433,  0.1600, -0.6468,  ..., -0.1073,  0.8064,  0.2949],\n",
       "         [-0.1529,  0.2756, -0.6074,  ..., -0.1499,  0.2579,  0.2592],\n",
       "         ...,\n",
       "         [-0.4552, -0.1479, -0.2224,  ...,  0.5286,  0.4948, -0.1547],\n",
       "         [-0.7590, -0.1594, -0.7258,  ..., -0.0609, -0.3791, -0.1477],\n",
       "         [-0.2573,  0.3954, -0.6496,  ..., -0.0445, -0.4129, -0.8336]],\n",
       "\n",
       "        [[ 0.4613,  0.3319,  0.1881,  ...,  0.1721,  0.4894,  0.2425],\n",
       "         [ 0.0433,  0.1600, -0.6468,  ..., -0.1073,  0.8064,  0.2949],\n",
       "         [-0.1529,  0.2756, -0.6074,  ..., -0.1499,  0.2579,  0.2592],\n",
       "         ...,\n",
       "         [-0.4552, -0.1479, -0.2224,  ...,  0.5286,  0.4948, -0.1547],\n",
       "         [-0.7590, -0.1594, -0.7258,  ..., -0.0609, -0.3791, -0.1477],\n",
       "         [-0.2573,  0.3954, -0.6496,  ..., -0.0445, -0.4129, -0.8336]]],\n",
       "       device='cuda:0')), (None, tensor([[[ 0.4167,  0.3340,  0.5423,  ...,  0.1023,  1.3198,  0.3052],\n",
       "         [ 0.4715,  0.2231, -0.8535,  ..., -0.0805,  1.7665,  0.2873],\n",
       "         [-0.1949,  0.8450, -0.6840,  ..., -0.3273,  0.3468,  0.3020],\n",
       "         ...,\n",
       "         [-0.6049,  0.4450, -0.5827,  ...,  0.9773,  0.7322, -0.3836],\n",
       "         [-0.7215,  0.3713, -1.0774,  ..., -0.4612, -0.6662, -0.4358],\n",
       "         [-0.0399,  0.8417, -1.3371,  ...,  0.2483, -0.1273, -1.4235]],\n",
       "\n",
       "        [[ 0.4167,  0.3340,  0.5423,  ...,  0.1023,  1.3198,  0.3052],\n",
       "         [ 0.4715,  0.2231, -0.8535,  ..., -0.0805,  1.7665,  0.2873],\n",
       "         [-0.1949,  0.8450, -0.6840,  ..., -0.3273,  0.3468,  0.3020],\n",
       "         ...,\n",
       "         [-0.6049,  0.4450, -0.5827,  ...,  0.9773,  0.7322, -0.3836],\n",
       "         [-0.7215,  0.3713, -1.0774,  ..., -0.4612, -0.6662, -0.4358],\n",
       "         [-0.0399,  0.8417, -1.3371,  ...,  0.2483, -0.1273, -1.4235]]],\n",
       "       device='cuda:0')), (None, tensor([[[ 0.1475,  0.1121,  0.0546,  ...,  0.2885,  0.2662, -0.0374],\n",
       "         [ 0.0163, -0.1748, -0.6494,  ...,  0.0017,  0.3509, -0.1153],\n",
       "         [-0.4036,  0.2115, -0.1836,  ..., -0.2556, -0.1631,  0.1092],\n",
       "         ...,\n",
       "         [-0.3856,  0.2207, -0.5330,  ...,  1.4514,  0.2145, -0.0159],\n",
       "         [-0.3360, -0.2049, -0.3714,  ..., -0.0233, -0.9410, -0.2662],\n",
       "         [-0.3295,  0.3569, -1.0050,  ...,  0.2207,  0.1530, -0.6822]],\n",
       "\n",
       "        [[ 0.1475,  0.1121,  0.0546,  ...,  0.2885,  0.2662, -0.0374],\n",
       "         [ 0.0163, -0.1748, -0.6494,  ...,  0.0017,  0.3509, -0.1153],\n",
       "         [-0.4036,  0.2115, -0.1836,  ..., -0.2556, -0.1631,  0.1092],\n",
       "         ...,\n",
       "         [-0.3856,  0.2207, -0.5330,  ...,  1.4514,  0.2145, -0.0159],\n",
       "         [-0.3360, -0.2049, -0.3714,  ..., -0.0233, -0.9410, -0.2662],\n",
       "         [-0.3295,  0.3569, -1.0050,  ...,  0.2207,  0.1530, -0.6822]]],\n",
       "       device='cuda:0'))], hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids = inputs[\"input_ids\"],\n",
    "        attention_mask = inputs[\"attention_mask\"],\n",
    "    )\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 26, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层的输出\n",
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
