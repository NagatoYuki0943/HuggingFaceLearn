{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/main/model_doc/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"bert-base-uncased\"\n",
    "sequence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/vocab.txt (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000223DFCAB210>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: fe814dfc-8c80-4552-9514-4470ad71102d)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer: BertTokenizer = BertTokenizer.from_pretrained(version)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'length', 'attention_mask'])\n",
      "tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102]], device='cuda:0')\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "tensor([12, 12], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [sequence] * 2,                     # 句子batch\n",
    "    truncation = True,                  # 超出max_length截断处理\n",
    "    padding = True,                     # 填充方式选择 [True, 'longest', 'max_length', 'do_not_pad']\n",
    "    # max_length = max_length,          # 最长长度,不设置默认为模型最大长度\n",
    "    add_special_tokens = True,          # text添加特殊key\n",
    "    return_length = True,               # 返回有效长度\n",
    "    return_overflowing_tokens = False,  # 返回所有的文本片段（由于文本比较长，默认情况下超过预设截断长度的token会被丢失。如果设置了return_overflowing_tokens=True则会返回所有的token片段）。\n",
    "    return_tensors = \"pt\"               # 返回数据格式 np pt tf jax\n",
    ").to(device, torch.float16)    # https://github.com/huggingface/transformers/issues/16359\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs[\"input_ids\"])\n",
    "print(inputs[\"attention_mask\"]) # 对应是否是文字\n",
    "print(inputs[\"length\"])         # 对应有效文字长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BertModel\n",
    "\n",
    "The bare Bert Model transformer outputting raw hidden-states without any specific head on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# > from_pretrained Parameters\n",
    "#   pretrained_model_name_or_path (`str` or `os.PathLike`, *optional*)\n",
    "#   model_args (sequence of positional arguments, *optional*)\n",
    "#   config (`Union[PretrainedConfig, str, os.PathLike]`, *optional*)\n",
    "#   state_dict (`Dict[str, torch.Tensor]`, *optional*)\n",
    "#   cache_dir (`Union[str, os.PathLike]`, *optional*)\n",
    "#   from_tf (`bool`, *optional*, defaults to `False`)\n",
    "#   from_flax (`bool`, *optional*, defaults to `False`)\n",
    "#   ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`)\n",
    "#   force_download (`bool`, *optional*, defaults to `False`)\n",
    "#   resume_download (`bool`, *optional*, defaults to `False`)\n",
    "#   proxies (`Dict[str, str]`, *optional*)\n",
    "#   output_loading_info(`bool`, *optional*, defaults to `False`)\n",
    "#   local_files_only(`bool`, *optional*, defaults to `False`)\n",
    "#   token (`str` or `bool`, *optional*)\n",
    "#   revision (`str`, *optional*, defaults to `\"main\"`)\n",
    "# > Parameters for big model inference\n",
    "#   low_cpu_mem_usage(`bool`, *optional*)\n",
    "#   torch_dtype: `torch.float16` or `torch.bfloat16` or `torch.float` or `\"auto\"`\n",
    "#   device_map (`str` or `Dict[str, Union[int, str, torch.device]]` or `int` or `torch.device`, *optional*)\n",
    "#   max_memory (`Dict`, *optional*)\n",
    "#   offload_folder (`str` or `os.PathLike`, *optional*)\n",
    "#   offload_state_dict (`bool`, *optional*)\n",
    "#   load_in_8bit (`bool`, *optional*, defaults to `False`)\n",
    "#   quantization_config (`Dict`, *optional*)\n",
    "#   subfolder (`str`, *optional*, defaults to `\"\"`)\n",
    "#   variant (`str`, *optional*)\n",
    "#   use_safetensors (`bool`, *optional*, defaults to `None`)\n",
    "#   **kwargs\n",
    "\n",
    "model: BertModel = BertModel.from_pretrained(version, torch_dtype=torch.float16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.3608,  0.2271, -0.3030,  ..., -0.4224,  0.6949,  0.6213],\n",
       "         [-0.3276, -0.3762, -0.5044,  ..., -0.3660,  1.1588, -0.2188],\n",
       "         [-0.4000, -0.4212,  0.4903,  ..., -0.4081,  0.8508, -0.0882],\n",
       "         ...,\n",
       "         [ 0.6786,  0.0645,  0.2290,  ..., -0.2903,  0.4909,  0.6316],\n",
       "         [-0.1088, -0.1644, -0.2961,  ...,  0.2168,  0.2916, -0.5030],\n",
       "         [ 0.7099,  0.4367, -0.4851,  ..., -0.0067, -0.1472, -0.2670]],\n",
       "\n",
       "        [[-0.3608,  0.2271, -0.3030,  ..., -0.4224,  0.6949,  0.6213],\n",
       "         [-0.3276, -0.3762, -0.5044,  ..., -0.3660,  1.1588, -0.2188],\n",
       "         [-0.4000, -0.4212,  0.4903,  ..., -0.4081,  0.8508, -0.0882],\n",
       "         ...,\n",
       "         [ 0.6786,  0.0645,  0.2290,  ..., -0.2903,  0.4909,  0.6316],\n",
       "         [-0.1088, -0.1644, -0.2961,  ...,  0.2168,  0.2916, -0.5030],\n",
       "         [ 0.7099,  0.4367, -0.4851,  ..., -0.0067, -0.1472, -0.2670]]],\n",
       "       device='cuda:0'), pooler_output=tensor([[-0.8232, -0.4768, -0.8892,  ..., -0.6265, -0.6798,  0.9165],\n",
       "        [-0.8232, -0.4768, -0.8892,  ..., -0.6265, -0.6798,  0.9165]],\n",
       "       device='cuda:0'), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids = inputs[\"input_ids\"],\n",
    "        attention_mask = inputs[\"attention_mask\"],\n",
    "    )\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层的输出\n",
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对文字长度进行pool\n",
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.cross_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoTokenizer\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/autoclass_tutorial#autotokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'length'])\n",
      "tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102]], device='cuda:0')\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "tensor([12, 12], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [sequence] * 2,                     # 句子batch\n",
    "    truncation = True,                  # 超出max_length截断处理\n",
    "    padding = True,                     # 填充方式选择 [True, 'longest', 'max_length', 'do_not_pad']\n",
    "    # max_length = max_length,          # 最长长度,不设置默认为模型最大长度\n",
    "    add_special_tokens = True,          # text添加特殊key\n",
    "    return_length = True,               # 返回有效长度\n",
    "    return_attention_mask = True,       # 返回attention_mask\n",
    "    return_overflowing_tokens = False,  # 返回所有的文本片段（由于文本比较长，默认情况下超过预设截断长度的token会被丢失。如果设置了return_overflowing_tokens=True则会返回所有的token片段）。\n",
    "    return_tensors = \"pt\",              # 返回数据格式 np pt tf jax\n",
    ").to(device)\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs[\"input_ids\"])\n",
    "print(inputs[\"attention_mask\"]) # 对应是否是文字\n",
    "print(inputs[\"length\"])         # 返回文字最长长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModel\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/model_doc/auto#transformers.AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: AutoModel = AutoModel.from_pretrained(version, torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.3608,  0.2271, -0.3030,  ..., -0.4224,  0.6949,  0.6213],\n",
       "         [-0.3276, -0.3762, -0.5044,  ..., -0.3660,  1.1588, -0.2188],\n",
       "         [-0.4000, -0.4212,  0.4903,  ..., -0.4081,  0.8508, -0.0882],\n",
       "         ...,\n",
       "         [ 0.6786,  0.0645,  0.2290,  ..., -0.2903,  0.4909,  0.6316],\n",
       "         [-0.1088, -0.1644, -0.2961,  ...,  0.2168,  0.2916, -0.5030],\n",
       "         [ 0.7099,  0.4367, -0.4851,  ..., -0.0067, -0.1472, -0.2670]],\n",
       "\n",
       "        [[-0.3608,  0.2271, -0.3030,  ..., -0.4224,  0.6949,  0.6213],\n",
       "         [-0.3276, -0.3762, -0.5044,  ..., -0.3660,  1.1588, -0.2188],\n",
       "         [-0.4000, -0.4212,  0.4903,  ..., -0.4081,  0.8508, -0.0882],\n",
       "         ...,\n",
       "         [ 0.6786,  0.0645,  0.2290,  ..., -0.2903,  0.4909,  0.6316],\n",
       "         [-0.1088, -0.1644, -0.2961,  ...,  0.2168,  0.2916, -0.5030],\n",
       "         [ 0.7099,  0.4367, -0.4851,  ..., -0.0067, -0.1472, -0.2670]]],\n",
       "       device='cuda:0'), pooler_output=tensor([[-0.8232, -0.4768, -0.8892,  ..., -0.6265, -0.6798,  0.9165],\n",
       "        [-0.8232, -0.4768, -0.8892,  ..., -0.6265, -0.6798,  0.9165]],\n",
       "       device='cuda:0'), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids = inputs[\"input_ids\"],\n",
    "        attention_mask = inputs[\"attention_mask\"],\n",
    "    )\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层的输出\n",
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对文字长度进行pool\n",
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.cross_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
