{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/model_doc/rwkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RwkvModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"RWKV/rwkv-4-169m-pile\"\n",
    "sequence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='RWKV/rwkv-4-169m-pile', vocab_size=50254, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(version)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'length'])\n",
      "tensor([[  510,  3158,  8516, 30013, 27287,   689,   253, 22658,  4370,    15],\n",
      "        [  510,  3158,  8516, 30013, 27287,   689,   253, 22658,  4370,    15]],\n",
      "       device='cuda:0')\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "tensor([10, 10], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [sequence] * 2,                     # 句子batch\n",
    "    truncation = True,                  # 超出max_length截断处理\n",
    "    # padding = True,                   # 填充方式选择 [True, 'longest', 'max_length', 'do_not_pad']\n",
    "    # max_length = max_length,          # 最长长度,不设置默认为模型最大长度\n",
    "    add_special_tokens = True,          # text添加特殊key\n",
    "    return_length = True,               # 返回有效长度\n",
    "    return_overflowing_tokens = False,  # 返回所有的文本片段（由于文本比较长，默认情况下超过预设截断长度的token会被丢失。如果设置了return_overflowing_tokens=True则会返回所有的token片段）。\n",
    "    return_tensors = \"pt\"               # 返回数据格式 np pt tf jax\n",
    ").to(device, torch.float16)    # https://github.com/huggingface/transformers/issues/16359\n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs[\"input_ids\"])\n",
    "print(inputs[\"attention_mask\"]) # 对应是否是文字\n",
    "print(inputs[\"length\"])         # 对应有效文字长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  510,  3158,  8516, 30013, 27287,   689,   253, 22658,  4370,    15],\n",
      "        [  510,  3158,  8516, 30013, 27287,   689,   253, 22658,  4370,    15]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RwkvModel\n",
    "\n",
    "The bare RWKV Model transformer outputting raw hidden-states without any specific head on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RwkvModel(\n",
       "  (embeddings): Embedding(50277, 768)\n",
       "  (blocks): ModuleList(\n",
       "    (0): RwkvBlock(\n",
       "      (pre_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): RwkvSelfAttention(\n",
       "        (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (receptance): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "      )\n",
       "      (feed_forward): RwkvFeedForward(\n",
       "        (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
       "        (key): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (receptance): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=3072, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1-11): 11 x RwkvBlock(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): RwkvSelfAttention(\n",
       "        (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
       "        (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (receptance): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "      )\n",
       "      (feed_forward): RwkvFeedForward(\n",
       "        (time_shift): ZeroPad2d((0, 0, 1, -1))\n",
       "        (key): Linear(in_features=768, out_features=3072, bias=False)\n",
       "        (receptance): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (value): Linear(in_features=3072, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_out): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: RwkvModel = RwkvModel.from_pretrained(version, torch_dtype=torch.float16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RwkvOutput(last_hidden_state=tensor([[[ 1.5777e-01, -2.7825e-01, -3.6044e-02,  ...,  2.7843e-01,\n",
       "          -6.8867e-04,  1.5167e-01],\n",
       "         [ 2.3544e-01, -2.6566e-01, -4.5412e-02,  ...,  4.5729e-01,\n",
       "          -5.9977e-03,  4.1358e-01],\n",
       "         [ 1.9137e-01, -3.2281e-01,  4.5989e-01,  ...,  6.7297e-01,\n",
       "           2.5942e-01,  2.5720e-01],\n",
       "         ...,\n",
       "         [-2.2506e-03, -4.2943e-01,  2.6817e-01,  ...,  7.3518e-01,\n",
       "           4.2219e-01,  2.4915e-01],\n",
       "         [ 4.0422e-01, -5.8881e-01, -1.1256e-01,  ...,  4.8805e-01,\n",
       "           1.5218e-01,  9.8003e-02],\n",
       "         [ 4.2592e-01, -3.9599e-01, -5.2124e-01,  ...,  3.4675e-01,\n",
       "           1.3662e-02,  2.8590e-01]],\n",
       "\n",
       "        [[ 1.5777e-01, -2.7825e-01, -3.6044e-02,  ...,  2.7843e-01,\n",
       "          -6.8867e-04,  1.5167e-01],\n",
       "         [ 2.3544e-01, -2.6566e-01, -4.5412e-02,  ...,  4.5729e-01,\n",
       "          -5.9977e-03,  4.1358e-01],\n",
       "         [ 1.9137e-01, -3.2281e-01,  4.5989e-01,  ...,  6.7297e-01,\n",
       "           2.5942e-01,  2.5720e-01],\n",
       "         ...,\n",
       "         [-2.2506e-03, -4.2943e-01,  2.6817e-01,  ...,  7.3518e-01,\n",
       "           4.2219e-01,  2.4915e-01],\n",
       "         [ 4.0422e-01, -5.8881e-01, -1.1256e-01,  ...,  4.8805e-01,\n",
       "           1.5218e-01,  9.8003e-02],\n",
       "         [ 4.2592e-01, -3.9599e-01, -5.2124e-01,  ...,  3.4675e-01,\n",
       "           1.3662e-02,  2.8590e-01]]], device='cuda:0'), state=[tensor([[[ 0.2225,  0.1188,  0.0896,  ...,  0.0326,  0.0078,  0.0295],\n",
       "         [-0.0662, -0.0499, -0.0377,  ...,  0.0017, -0.0274, -0.1174],\n",
       "         [-0.0286, -0.0091,  0.0332,  ...,  0.0875,  0.0303, -0.0792],\n",
       "         ...,\n",
       "         [-0.9113, -0.1874,  0.0637,  ...,  0.0963,  0.0380,  0.1952],\n",
       "         [ 0.0245, -0.0833, -0.0593,  ..., -0.0113, -0.0170,  0.1996],\n",
       "         [ 0.1317,  0.1351,  0.0662,  ..., -0.0175, -0.0201,  0.2572]],\n",
       "\n",
       "        [[ 0.2225,  0.1188,  0.0896,  ...,  0.0326,  0.0078,  0.0295],\n",
       "         [-0.0662, -0.0499, -0.0377,  ...,  0.0017, -0.0274, -0.1174],\n",
       "         [-0.0286, -0.0091,  0.0332,  ...,  0.0875,  0.0303, -0.0792],\n",
       "         ...,\n",
       "         [-0.9113, -0.1874,  0.0637,  ...,  0.0963,  0.0380,  0.1952],\n",
       "         [ 0.0245, -0.0833, -0.0593,  ..., -0.0113, -0.0170,  0.1996],\n",
       "         [ 0.1317,  0.1351,  0.0662,  ..., -0.0175, -0.0201,  0.2572]]],\n",
       "       device='cuda:0'), tensor([[[ 0.3993,  0.3254,  0.4018,  ...,  0.1507,  0.1583,  0.2923],\n",
       "         [-0.1028, -0.0924, -0.1305,  ..., -0.0140,  0.0261, -0.0715],\n",
       "         [-0.0307, -0.0851, -0.1221,  ...,  0.0778,  0.0400, -0.0822],\n",
       "         ...,\n",
       "         [-0.2842, -0.3018, -0.0330,  ...,  0.3348,  0.2000,  0.2374],\n",
       "         [-0.0424,  0.0055, -0.0544,  ...,  0.0263,  0.0241,  0.0158],\n",
       "         [ 0.0245,  0.0535,  0.1025,  ...,  0.0381,  0.0609,  0.1063]],\n",
       "\n",
       "        [[ 0.3993,  0.3254,  0.4018,  ...,  0.1507,  0.1583,  0.2923],\n",
       "         [-0.1028, -0.0924, -0.1305,  ..., -0.0140,  0.0261, -0.0715],\n",
       "         [-0.0307, -0.0851, -0.1221,  ...,  0.0778,  0.0400, -0.0822],\n",
       "         ...,\n",
       "         [-0.2842, -0.3018, -0.0330,  ...,  0.3348,  0.2000,  0.2374],\n",
       "         [-0.0424,  0.0055, -0.0544,  ...,  0.0263,  0.0241,  0.0158],\n",
       "         [ 0.0245,  0.0535,  0.1025,  ...,  0.0381,  0.0609,  0.1063]]],\n",
       "       device='cuda:0'), tensor([[[-3.7764e-01,  1.2790e+00,  9.9386e-02,  ...,  9.0598e-01,\n",
       "          -5.2200e-01,  4.9302e+00],\n",
       "         [ 3.4368e-01, -1.0379e+00, -3.6716e-01,  ...,  9.7719e+00,\n",
       "           3.0500e-01, -2.7224e+00],\n",
       "         [-4.0453e+00, -4.5327e-03,  3.5354e+00,  ..., -2.0788e+00,\n",
       "           3.4048e+00,  4.3102e+00],\n",
       "         ...,\n",
       "         [-1.9081e-02,  2.5543e+00,  1.2049e-01,  ...,  2.2628e-01,\n",
       "          -1.3573e+00, -1.6883e+01],\n",
       "         [-4.1451e-01,  8.4745e-01,  6.7255e-02,  ...,  3.5320e+00,\n",
       "          -9.1527e-01, -1.9499e+00],\n",
       "         [ 1.0927e+00, -1.3682e+00,  7.1420e-01,  ..., -1.8595e+00,\n",
       "           1.8236e+00, -9.8203e-01]],\n",
       "\n",
       "        [[-3.7764e-01,  1.2790e+00,  9.9386e-02,  ...,  9.0598e-01,\n",
       "          -5.2200e-01,  4.9302e+00],\n",
       "         [ 3.4368e-01, -1.0379e+00, -3.6716e-01,  ...,  9.7719e+00,\n",
       "           3.0500e-01, -2.7224e+00],\n",
       "         [-4.0453e+00, -4.5327e-03,  3.5354e+00,  ..., -2.0788e+00,\n",
       "           3.4048e+00,  4.3102e+00],\n",
       "         ...,\n",
       "         [-1.9081e-02,  2.5543e+00,  1.2049e-01,  ...,  2.2628e-01,\n",
       "          -1.3573e+00, -1.6883e+01],\n",
       "         [-4.1451e-01,  8.4745e-01,  6.7255e-02,  ...,  3.5320e+00,\n",
       "          -9.1527e-01, -1.9499e+00],\n",
       "         [ 1.0927e+00, -1.3682e+00,  7.1420e-01,  ..., -1.8595e+00,\n",
       "           1.8236e+00, -9.8203e-01]]], device='cuda:0'), tensor([[[1.3668, 1.2461, 1.6069,  ..., 1.3452, 2.7215, 2.7309],\n",
       "         [1.0209, 1.0398, 2.5013,  ..., 3.2686, 1.7853, 2.0837],\n",
       "         [4.2172, 1.1974, 2.3199,  ..., 1.5115, 2.5459, 1.4387],\n",
       "         ...,\n",
       "         [1.0000, 1.0898, 1.9601,  ..., 1.0278, 1.0345, 1.1754],\n",
       "         [1.1721, 2.3865, 1.9579,  ..., 1.0255, 1.0584, 1.0505],\n",
       "         [1.0197, 1.4019, 1.8378,  ..., 1.0375, 1.0058, 1.2148]],\n",
       "\n",
       "        [[1.3668, 1.2461, 1.6069,  ..., 1.3452, 2.7215, 2.7309],\n",
       "         [1.0209, 1.0398, 2.5013,  ..., 3.2686, 1.7853, 2.0837],\n",
       "         [4.2172, 1.1974, 2.3199,  ..., 1.5115, 2.5459, 1.4387],\n",
       "         ...,\n",
       "         [1.0000, 1.0898, 1.9601,  ..., 1.0278, 1.0345, 1.1754],\n",
       "         [1.1721, 2.3865, 1.9579,  ..., 1.0255, 1.0584, 1.0505],\n",
       "         [1.0197, 1.4019, 1.8378,  ..., 1.0375, 1.0058, 1.2148]]],\n",
       "       device='cuda:0'), tensor([[[ 3.7085,  1.3083,  3.1712,  ...,  8.8148,  6.7917,  9.8952],\n",
       "         [ 7.6113,  1.7623,  1.1369,  ..., 10.8260,  1.8330,  9.8337],\n",
       "         [ 1.0394,  2.5499,  4.2184,  ...,  3.8327,  9.5100, 12.2673],\n",
       "         ...,\n",
       "         [ 1.9713, -4.1425,  0.4731,  ..., 10.8562,  2.8128,  3.5615],\n",
       "         [-1.2553,  1.1836, -0.5565,  ...,  6.3711, -0.1585,  3.5553],\n",
       "         [ 2.6875, -0.8453,  3.0236,  ...,  9.0089,  2.5503,  5.8857]],\n",
       "\n",
       "        [[ 3.7085,  1.3083,  3.1712,  ...,  8.8148,  6.7917,  9.8952],\n",
       "         [ 7.6113,  1.7623,  1.1369,  ..., 10.8260,  1.8330,  9.8337],\n",
       "         [ 1.0394,  2.5499,  4.2184,  ...,  3.8327,  9.5100, 12.2673],\n",
       "         ...,\n",
       "         [ 1.9713, -4.1425,  0.4731,  ..., 10.8562,  2.8128,  3.5615],\n",
       "         [-1.2553,  1.1836, -0.5565,  ...,  6.3711, -0.1585,  3.5553],\n",
       "         [ 2.6875, -0.8453,  3.0236,  ...,  9.0089,  2.5503,  5.8857]]],\n",
       "       device='cuda:0')], hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids = inputs[\"input_ids\"],\n",
    "        attention_mask = inputs[\"attention_mask\"],\n",
    "    )\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层的输出\n",
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
