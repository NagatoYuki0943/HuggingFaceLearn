{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoformerConfig, AutoformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoformerConfig {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"autocorrelation_factor\": 3,\n",
       "  \"cardinality\": [\n",
       "    0\n",
       "  ],\n",
       "  \"context_length\": null,\n",
       "  \"d_model\": 64,\n",
       "  \"decoder_attention_heads\": 2,\n",
       "  \"decoder_ffn_dim\": 32,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 2,\n",
       "  \"distribution_output\": \"student_t\",\n",
       "  \"dropout\": 0.1,\n",
       "  \"embedding_dimension\": [\n",
       "    0\n",
       "  ],\n",
       "  \"encoder_attention_heads\": 2,\n",
       "  \"encoder_ffn_dim\": 32,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"feature_size\": 9,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 1,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label_length\": 10,\n",
       "  \"lags_sequence\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7\n",
       "  ],\n",
       "  \"loss\": \"nll\",\n",
       "  \"model_type\": \"autoformer\",\n",
       "  \"moving_average\": 25,\n",
       "  \"num_dynamic_real_features\": 0,\n",
       "  \"num_parallel_samples\": 100,\n",
       "  \"num_static_categorical_features\": 0,\n",
       "  \"num_static_real_features\": 0,\n",
       "  \"num_time_features\": 0,\n",
       "  \"prediction_length\": null,\n",
       "  \"scaling\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a default Autoformer configuration\n",
    "config = AutoformerConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.context_length    = 24    # from huggingface/autoformer-tourism-monthly\n",
    "config.prediction_length = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoformerModel(\n",
       "  (scaler): AutoformerMeanScaler()\n",
       "  (encoder): AutoformerEncoder(\n",
       "    (value_embedding): AutoformerValueEmbedding(\n",
       "      (value_projection): Linear(in_features=9, out_features=64, bias=False)\n",
       "    )\n",
       "    (embed_positions): AutoformerSinusoidalPositionalEmbedding(48, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x AutoformerEncoderLayer(\n",
       "        (self_attn): AutoformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): AutoformerLayernorm(\n",
       "          (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decomp1): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (decomp2): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): AutoformerDecoder(\n",
       "    (value_embedding): AutoformerValueEmbedding(\n",
       "      (value_projection): Linear(in_features=9, out_features=64, bias=False)\n",
       "    )\n",
       "    (embed_positions): AutoformerSinusoidalPositionalEmbedding(48, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x AutoformerDecoderLayer(\n",
       "        (self_attn): AutoformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): AutoformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): AutoformerLayernorm(\n",
       "          (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decomp1): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (decomp2): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (decomp3): AutoformerSeriesDecompositionLayer(\n",
       "          (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "        )\n",
       "        (trend_projection): Conv1d(64, 9, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (seasonality_projection): Linear(in_features=64, out_features=9, bias=True)\n",
       "  )\n",
       "  (decomposition_layer): AutoformerSeriesDecompositionLayer(\n",
       "    (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = AutoformerModel(config).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoformerConfig {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"autocorrelation_factor\": 3,\n",
       "  \"cardinality\": [\n",
       "    0\n",
       "  ],\n",
       "  \"context_length\": 24,\n",
       "  \"d_model\": 64,\n",
       "  \"decoder_attention_heads\": 2,\n",
       "  \"decoder_ffn_dim\": 32,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 2,\n",
       "  \"distribution_output\": \"student_t\",\n",
       "  \"dropout\": 0.1,\n",
       "  \"embedding_dimension\": [\n",
       "    0\n",
       "  ],\n",
       "  \"encoder_attention_heads\": 2,\n",
       "  \"encoder_ffn_dim\": 32,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"feature_size\": 9,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 1,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label_length\": 10,\n",
       "  \"lags_sequence\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7\n",
       "  ],\n",
       "  \"loss\": \"nll\",\n",
       "  \"model_type\": \"autoformer\",\n",
       "  \"moving_average\": 25,\n",
       "  \"num_dynamic_real_features\": 0,\n",
       "  \"num_parallel_samples\": 100,\n",
       "  \"num_static_categorical_features\": 0,\n",
       "  \"num_static_real_features\": 0,\n",
       "  \"num_time_features\": 0,\n",
       "  \"prediction_length\": 24,\n",
       "  \"scaling\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
